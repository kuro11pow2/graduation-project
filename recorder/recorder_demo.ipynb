{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 주의사항\r\n",
    "1. windows 환경에서는 빌드된 ffmpeg 실행파일을 환경 변수 > Path 에 등록해야 한다.\r\n",
    "2. gym 0.18.0 에는 video로 저장할 수 없는 버그가 있다. [refer](https://github.com/openai/gym/issues/1925)\r\n",
    "3. wrappers.Monitor의 video_callable 파라미터로 녹화할 에피소드를 지정할 수 있다. capture_frame이 호출되는 시점은 _after_step이다.  \r\n",
    "\r\n",
    "* Monitor wrapper에서 반환된 env는 step을 실행할 때 _before_step(action), env.step(action), _after_step(action) 순으로 실행 후 return observatoin, reward ... 한다.  \r\n",
    "* 프레임 캡쳐는 위와 같이 매 스탭 진행된다. \r\n",
    "* recorder를 종료하고 재시작하는 것은 reset_video_recorder에서 담당한다.\r\n",
    "  * 먼저, 열려있는 recorder를 종료한다.\r\n",
    "  * 이번 에피소드가 녹화할 에피소드라면 파일을 생성한다.\r\n",
    "  * 학습을 진행하면 파일에 프레임이 저장된다.\r\n",
    "* n_epi를 녹화하려면 n_epi + 1이 시작된 이후, 또는 안전하게 n_epi + 2까지 가서 녹화해야 한다."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from actor_critic import *\r\n",
    "from recorder import *\r\n",
    "\r\n",
    "from torch.distributions import Categorical"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "recorder = Recorder(gym.make('CartPole-v1'))\r\n",
    "env = recorder.wrapped_env()\r\n",
    "# policy 대신 model class를 만들었다. \r\n",
    "# actor-critic 둘 다 있어야 하기 때문에 policy와 value를 둘 다 얻을 수 있게 함.\r\n",
    "model = ActorCritic()    \r\n",
    "print_interval = 20\r\n",
    "score = 0.0\r\n",
    "\r\n",
    "for n_epi in range(1000):\r\n",
    "    done = False\r\n",
    "    s = env.reset()\r\n",
    "    while not done:\r\n",
    "        for t in range(n_rollout):\r\n",
    "            # 확률 분포 구하고\r\n",
    "            prob = model.pi(torch.from_numpy(s).float())\r\n",
    "            # 확률 분포 모델 만들고\r\n",
    "            m = Categorical(prob)\r\n",
    "            # 샘플링하고\r\n",
    "            a = m.sample().item()\r\n",
    "            # 환경에 넘겨주고 다음 observation 얻고\r\n",
    "            s_prime, r, done, info = env.step(a)\r\n",
    "            # TD의 경우 매번 학습이 가능하지만 모아서 batch learning 하니까 학습이 더 잘 됐다.\r\n",
    "            model.put_data((s,a,r,s_prime,done))\r\n",
    "            \r\n",
    "            s = s_prime\r\n",
    "            score += r\r\n",
    "            \r\n",
    "            if done:\r\n",
    "                break                     \r\n",
    "        \r\n",
    "        model.train_net()\r\n",
    "\r\n",
    "    if score/print_interval > 400:\r\n",
    "        recorder.update([n_epi + 1])\r\n",
    "        if len(recorder.n_epi_set) >= 5:\r\n",
    "            env.reset() # 마지막 에피소드 비디오 마무리\r\n",
    "            break\r\n",
    "\r\n",
    "    if n_epi%print_interval==0 and n_epi!=0:\r\n",
    "        print(\"# of episode :{}, avg score : {:.1f}\".format(n_epi, score/print_interval))\r\n",
    "        score = 0.0\r\n",
    "        \r\n",
    "env.close()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('py38-pytorch-gpu': conda)"
  },
  "interpreter": {
   "hash": "92bb61e8f2b0dcdaa21cd71aad1d97e3da046ad8a677ac321cbd25d595832889"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}