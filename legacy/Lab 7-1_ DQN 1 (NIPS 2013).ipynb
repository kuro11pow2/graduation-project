{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"(OLD) Lab 7-1: DQN 1 (NIPS 2013).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"WQYlKIksWrHP"},"source":["# 최초 1회 실행"]},{"cell_type":"code","metadata":{"id":"7rIhm3T_A3fm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615297447205,"user_tz":-540,"elapsed":86155,"user":{"displayName":"MinGyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg37lY1KZUyNC5LnAgjlz5ycbAgYKsMFb00DrnY=s64","userId":"17915453342275559692"}},"outputId":"a7c1682a-43f0-4cf8-f0f6-134f1bd31e86"},"source":["# print('### OS ###')\r\n","# !cat /etc/issue.net\r\n","\r\n","# print('### CPU ###')\r\n","# !cat /proc/cpuinfo\r\n","\r\n","# print('### MEM ###')\r\n","# !cat /proc/meminfo\r\n","\r\n","# print('### DISK ###')\r\n","# !df -h\r\n","\r\n","# print('### GPU ###')\r\n","# !nvidia-smi\r\n","\r\n","\r\n","!pip uninstall -y tensorflow\r\n","!pip install tensorflow==1.15"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-2.4.1:\n","  Successfully uninstalled tensorflow-2.4.1\n","Collecting tensorflow==1.15\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n","\u001b[K     |████████████████████████████████| 412.3MB 22kB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 37.4MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n","Collecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 4.9MB/s \n","\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.10.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 28.0MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (54.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=17c46b566de7827948f52df2dc4b6658d6bfdaa15178a705cc2ba28652d8de6c\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: gast, tensorboard, keras-applications, tensorflow-estimator, tensorflow\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mN1Z3HbSB4kB","executionInfo":{"status":"ok","timestamp":1615297461357,"user_tz":-540,"elapsed":100270,"user":{"displayName":"MinGyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg37lY1KZUyNC5LnAgjlz5ycbAgYKsMFb00DrnY=s64","userId":"17915453342275559692"}},"outputId":"1f67dbfa-18df-46a8-f955-7bc06c35be79"},"source":["!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\r\n","!pip install -U colabgymrender"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting colabgymrender\n","  Downloading https://files.pythonhosted.org/packages/b2/97/eab3f4ef460cc79b811c37c3be2d05967696605774868b6556e04e6ae6f8/colabgymrender-1.0.8.tar.gz\n","Requirement already satisfied, skipping upgrade: moviepy in /usr/local/lib/python3.7/dist-packages (from colabgymrender) (0.2.3.5)\n","Requirement already satisfied, skipping upgrade: ipython in /usr/local/lib/python3.7/dist-packages (from colabgymrender) (5.5.0)\n","Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.7/dist-packages (from colabgymrender) (4.1.2.30)\n","Collecting pyvirtualdisplay\n","  Downloading https://files.pythonhosted.org/packages/19/88/7a198a5ee3baa3d547f5a49574cd8c3913b216f5276b690b028f89ffb325/PyVirtualDisplay-2.1-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (4.4.2)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (1.19.5)\n","Requirement already satisfied, skipping upgrade: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (4.41.1)\n","Requirement already satisfied, skipping upgrade: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (2.4.1)\n","Requirement already satisfied, skipping upgrade: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->colabgymrender) (0.8.1)\n","Requirement already satisfied, skipping upgrade: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->colabgymrender) (0.7.5)\n","Requirement already satisfied, skipping upgrade: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->colabgymrender) (2.6.1)\n","Requirement already satisfied, skipping upgrade: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->colabgymrender) (54.0.0)\n","Requirement already satisfied, skipping upgrade: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->colabgymrender) (4.8.0)\n","Requirement already satisfied, skipping upgrade: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->colabgymrender) (1.0.18)\n","Requirement already satisfied, skipping upgrade: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->colabgymrender) (5.0.5)\n","Collecting EasyProcess\n","  Downloading https://files.pythonhosted.org/packages/48/3c/75573613641c90c6d094059ac28adb748560d99bd27ee6f80cce398f404e/EasyProcess-0.3-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy->colabgymrender) (7.0.0)\n","Requirement already satisfied, skipping upgrade: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->colabgymrender) (0.7.0)\n","Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->colabgymrender) (0.2.5)\n","Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->colabgymrender) (1.15.0)\n","Requirement already satisfied, skipping upgrade: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->colabgymrender) (0.2.0)\n","Building wheels for collected packages: colabgymrender\n","  Building wheel for colabgymrender (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for colabgymrender: filename=colabgymrender-1.0.8-cp37-none-any.whl size=2511 sha256=ba2a1f3a691f84a47c6ddaadc9f2342e2ab71e8bb44ca6aa8697180f3f9bf3cc\n","  Stored in directory: /root/.cache/pip/wheels/8a/d1/e8/ef1d4f6e536cc6b965b28c859ccd2a7f7ab123b94ef4007712\n","Successfully built colabgymrender\n","Installing collected packages: EasyProcess, pyvirtualdisplay, colabgymrender\n","Successfully installed EasyProcess-0.3 colabgymrender-1.0.8 pyvirtualdisplay-2.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"S7nwNhbPUF1x"},"source":["# 초기 설정\r\n","* 환경 만들기  \r\n","* 텐서플로우1 설정  \r\n","* colab에서의 OpenAI 비디오 렌더링"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DadeWo-NBD8S","executionInfo":{"status":"ok","timestamp":1615297502009,"user_tz":-540,"elapsed":577,"user":{"displayName":"MinGyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg37lY1KZUyNC5LnAgjlz5ycbAgYKsMFb00DrnY=s64","userId":"17915453342275559692"}},"outputId":"9dd46bb0-bfc6-4a85-b812-e1ab83bb92c3"},"source":["import tensorflow as tf\r\n","print(tf.__version__)\r\n","\r\n","import torch\r\n","import torchvision\r\n","import torchtext\r\n","print(torch.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["1.15.0\n","1.8.0+cu101\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sQ7C3rzrCcTW","executionInfo":{"status":"ok","timestamp":1615297502867,"user_tz":-540,"elapsed":1027,"user":{"displayName":"MinGyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg37lY1KZUyNC5LnAgjlz5ycbAgYKsMFb00DrnY=s64","userId":"17915453342275559692"}}},"source":["# 초기 설정 (텐서플로우1 사용, colab 렌더링 포함)\r\n","import tensorflow as tf\r\n","# import tensorflow.compat.v1 as tf\r\n","#tf.disable_v2_behavior()\r\n","\r\n","import numpy as np\r\n","import random\r\n","from collections import deque\r\n","import matplotlib.pyplot as plt\r\n","\r\n","import gym\r\n","env = gym.make('CartPole-v1')\r\n","env._max_episode_steps = 10001\r\n","\r\n","# from colabgymrender.recorder import Recorder\r\n","# directory = './video'\r\n","# env = Recorder(env, directory)\r\n","\r\n","REWARD = -100\r\n","MAX_EPI = 2000\r\n","H_SIZE = 10\r\n","L_RATE = 1e-1\r\n","\r\n","input_size = env.observation_space.shape[0]\r\n","output_size = env.action_space.n\r\n","\r\n","dis = 0.9\r\n","REPLAY_MEMORY = 50000\r\n","results = []"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e9AbFgm6nRK6"},"source":["# 네트워크"]},{"cell_type":"code","metadata":{"id":"7bRSlmrjnSwy","executionInfo":{"status":"ok","timestamp":1615297502868,"user_tz":-540,"elapsed":479,"user":{"displayName":"MinGyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg37lY1KZUyNC5LnAgjlz5ycbAgYKsMFb00DrnY=s64","userId":"17915453342275559692"}}},"source":["class DQN:\r\n","  def __init__(self, session, input_size, output_size, name=\"main\"):\r\n","    self.session = session\r\n","    self.input_size = input_size\r\n","    self.output_size = output_size\r\n","    self.net_name = name\r\n","    self._build_network()\r\n","\r\n","  def _build_network(self, h_size=H_SIZE, l_rate=L_RATE):\r\n","    with tf.variable_scope(self.net_name):\r\n","      self._X = tf.placeholder(tf.float32, [None, self.input_size], \r\n","                               name=\"input_x\")\r\n","\r\n","      # weights의 첫 레이어\r\n","      W1 = tf.get_variable(\"W1\", shape=[self.input_size, h_size], \r\n","                           initializer=tf.contrib.layers.xavier_initializer())\r\n","      layer1 = tf.nn.tanh(tf.matmul(self._X, W1))\r\n","\r\n","      # 두 번째 레이어\r\n","      W2 = tf.get_variable(\"W2\", shape=[h_size, self.output_size],\r\n","                           initializer=tf.contrib.layers.xavier_initializer())\r\n","\r\n","      # Q 예측\r\n","      self._Qpred = tf.matmul(layer1, W2)\r\n","\r\n","    # a로 훈련하는 네트워크를 정의해야 한다.\r\n","    # policy\r\n","    self._Y = tf.placeholder(shape=[None, self.output_size], dtype=tf.float32)\r\n","\r\n","    # loss function\r\n","    self._loss = tf.reduce_mean(tf.square(self._Y - self._Qpred))\r\n","    \r\n","    # 훈련\r\n","    self._train = tf.train.AdamOptimizer(learning_rate=l_rate).minimize(self._loss)\r\n","\r\n","  def predict(self, state):\r\n","    x = np.reshape(state, [1, self.input_size])\r\n","    return self.session.run(self._Qpred, feed_dict={self._X: x})\r\n","  \r\n","  def update(self, x_stack, y_stack):\r\n","    return self.session.run([self._loss, self._train], \r\n","                            feed_dict={self._X: x_stack, self._Y: y_stack})"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y-w4H4X8qMHr"},"source":["# Replay buffer로 훈련"]},{"cell_type":"code","metadata":{"id":"4Z5qthK_qPhB","executionInfo":{"status":"ok","timestamp":1615297503211,"user_tz":-540,"elapsed":377,"user":{"displayName":"MinGyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg37lY1KZUyNC5LnAgjlz5ycbAgYKsMFb00DrnY=s64","userId":"17915453342275559692"}}},"source":["# train_batch로 단순하게 훈련\r\n","def simple_replay_train(DQN, train_batch):\r\n","  x_stack = np.empty(0).reshape(0, DQN.input_size)\r\n","  y_stack = np.empty(0).reshape(0, DQN.output_size)\r\n","\r\n","  # 버퍼에 저장된 정보를 가져온다\r\n","  for state, action, reward, next_state, done in train_batch:\r\n","    Q = DQN.predict(state)\r\n","\r\n","    # 종료 확인\r\n","    if done:\r\n","      Q[0, action] = reward\r\n","    else:\r\n","      Q[0, action] = reward + dis * np.max(DQN.predict(next_state))\r\n","    \r\n","    y_stack = np.vstack([y_stack, Q])\r\n","    x_stack = np.vstack([x_stack, state])\r\n","\r\n","  return DQN.update(x_stack, y_stack)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fWmfudGrrUn8"},"source":["# bot play"]},{"cell_type":"code","metadata":{"id":"EMERLUG5rWw2","executionInfo":{"status":"ok","timestamp":1615297507968,"user_tz":-540,"elapsed":584,"user":{"displayName":"MinGyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg37lY1KZUyNC5LnAgjlz5ycbAgYKsMFb00DrnY=s64","userId":"17915453342275559692"}}},"source":["def bot_play(mainDQN):\r\n","  # 우리의 훈련된 네트워크의 액션을 본다\r\n","  s = env.reset()\r\n","  reward_sum = 0\r\n","  while True:\r\n","    # env.render()\r\n","    a = np.argmax(mainDQN.predict(s))\r\n","    s, reward, done, _ = env.step(a)\r\n","    reward_sum += reward\r\n","\r\n","    if done:\r\n","      print(\"Total score: {}\".format(reward_sum))\r\n","      # env.play()\r\n","      break\r\n","  \r\n","  "],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D85DYqaortUi"},"source":["# main"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"wtkKg3xNruU-","executionInfo":{"status":"ok","timestamp":1615297598665,"user_tz":-540,"elapsed":81534,"user":{"displayName":"MinGyu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg37lY1KZUyNC5LnAgjlz5ycbAgYKsMFb00DrnY=s64","userId":"17915453342275559692"}},"outputId":"f11ccfa6-4c2d-409c-a772-c0164f79a254"},"source":["def main():\r\n","  max_episodes = MAX_EPI\r\n","\r\n","  # 이전 관찰을 replay memory에 저장한다.\r\n","  replay_buffer = deque()\r\n","  \r\n","  with tf.Session() as sess:\r\n","    mainDQN = DQN(sess, input_size, output_size)\r\n","    tf.global_variables_initializer().run()\r\n","\r\n","    for episode in range(max_episodes):\r\n","      e = 1. / ((episode / 10) + 1)\r\n","      done = False\r\n","      step_count = 0\r\n","\r\n","      state = env.reset()\r\n","\r\n","      while not done:\r\n","        # e-greedy 방식으로 action 선택\r\n","        if np.random.rand(1) < e:\r\n","          action = env.action_space.sample()\r\n","        else:\r\n","          action = np.argmax(mainDQN.predict(state))\r\n","\r\n","        # 환경에서 새 상태와 보상을 얻는다.\r\n","        next_state, reward, done, _ = env.step(action)\r\n","        \r\n","        # 패널티\r\n","        if done:\r\n","          reward = REWARD\r\n","\r\n","        # 버퍼에 관찰 결과를 저장한다.\r\n","        replay_buffer.append((state, action, reward, next_state, done))\r\n","        if len(replay_buffer) > REPLAY_MEMORY:\r\n","          replay_buffer.popleft()\r\n","        \r\n","        state = next_state\r\n","        step_count += 1\r\n","        if step_count > 10000:\r\n","          break\r\n","\r\n","      print(\"Episode: {} steps: {}\".format(episode, step_count))\r\n","      results.append(step_count)\r\n","\r\n","      if step_count > 10000:\r\n","          break\r\n","          \r\n","      # 10번마다 훈련한다.\r\n","      if episode % 10 == 1:\r\n","        # 버퍼에서 랜덤 배치를 얻는다.\r\n","        for _ in range(50):\r\n","          minibatch = random.sample(replay_buffer, 10)\r\n","          loss, _ = simple_replay_train(mainDQN, minibatch)\r\n","        print(\"Loss: \", loss)\r\n","    bot_play(mainDQN)\r\n","    plt.title(\"(2013) Total step count on each episode\")\r\n","    plt.plot(range(len(results)), results)\r\n","    plt.show()\r\n","\r\n","main()\r\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","Episode: 0 steps: 54\n","Episode: 1 steps: 42\n","Loss:  2.1037045\n","Episode: 2 steps: 20\n","Episode: 3 steps: 54\n","Episode: 4 steps: 28\n","Episode: 5 steps: 11\n","Episode: 6 steps: 35\n","Episode: 7 steps: 30\n","Episode: 8 steps: 59\n","Episode: 9 steps: 61\n","Episode: 10 steps: 77\n","Episode: 11 steps: 56\n","Loss:  8.231886\n","Episode: 12 steps: 15\n","Episode: 13 steps: 11\n","Episode: 14 steps: 9\n","Episode: 15 steps: 10\n","Episode: 16 steps: 8\n","Episode: 17 steps: 10\n","Episode: 18 steps: 8\n","Episode: 19 steps: 12\n","Episode: 20 steps: 9\n","Episode: 21 steps: 11\n","Loss:  389.33194\n","Episode: 22 steps: 10\n","Episode: 23 steps: 11\n","Episode: 24 steps: 13\n","Episode: 25 steps: 10\n","Episode: 26 steps: 11\n","Episode: 27 steps: 9\n","Episode: 28 steps: 12\n","Episode: 29 steps: 9\n","Episode: 30 steps: 9\n","Episode: 31 steps: 10\n","Loss:  10.797875\n","Episode: 32 steps: 26\n","Episode: 33 steps: 34\n","Episode: 34 steps: 18\n","Episode: 35 steps: 26\n","Episode: 36 steps: 36\n","Episode: 37 steps: 30\n","Episode: 38 steps: 35\n","Episode: 39 steps: 48\n","Episode: 40 steps: 34\n","Episode: 41 steps: 28\n","Loss:  1.7343276\n","Episode: 42 steps: 10\n","Episode: 43 steps: 13\n","Episode: 44 steps: 11\n","Episode: 45 steps: 14\n","Episode: 46 steps: 17\n","Episode: 47 steps: 13\n","Episode: 48 steps: 19\n","Episode: 49 steps: 9\n","Episode: 50 steps: 9\n","Episode: 51 steps: 16\n","Loss:  5.6555433\n","Episode: 52 steps: 41\n","Episode: 53 steps: 20\n","Episode: 54 steps: 29\n","Episode: 55 steps: 23\n","Episode: 56 steps: 60\n","Episode: 57 steps: 22\n","Episode: 58 steps: 20\n","Episode: 59 steps: 41\n","Episode: 60 steps: 21\n","Episode: 61 steps: 54\n","Loss:  1005.62646\n","Episode: 62 steps: 42\n","Episode: 63 steps: 24\n","Episode: 64 steps: 22\n","Episode: 65 steps: 25\n","Episode: 66 steps: 53\n","Episode: 67 steps: 40\n","Episode: 68 steps: 29\n","Episode: 69 steps: 44\n","Episode: 70 steps: 42\n","Episode: 71 steps: 28\n","Loss:  4.0791445\n","Episode: 72 steps: 30\n","Episode: 73 steps: 24\n","Episode: 74 steps: 42\n","Episode: 75 steps: 68\n","Episode: 76 steps: 31\n","Episode: 77 steps: 22\n","Episode: 78 steps: 42\n","Episode: 79 steps: 42\n","Episode: 80 steps: 24\n","Episode: 81 steps: 48\n","Loss:  542.0708\n","Episode: 82 steps: 28\n","Episode: 83 steps: 23\n","Episode: 84 steps: 29\n","Episode: 85 steps: 49\n","Episode: 86 steps: 41\n","Episode: 87 steps: 58\n","Episode: 88 steps: 56\n","Episode: 89 steps: 30\n","Episode: 90 steps: 23\n","Episode: 91 steps: 50\n","Loss:  2.748345\n","Episode: 92 steps: 9\n","Episode: 93 steps: 10\n","Episode: 94 steps: 9\n","Episode: 95 steps: 8\n","Episode: 96 steps: 8\n","Episode: 97 steps: 9\n","Episode: 98 steps: 9\n","Episode: 99 steps: 14\n","Episode: 100 steps: 9\n","Episode: 101 steps: 12\n","Loss:  485.71466\n","Episode: 102 steps: 43\n","Episode: 103 steps: 28\n","Episode: 104 steps: 24\n","Episode: 105 steps: 24\n","Episode: 106 steps: 19\n","Episode: 107 steps: 26\n","Episode: 108 steps: 23\n","Episode: 109 steps: 24\n","Episode: 110 steps: 23\n","Episode: 111 steps: 20\n","Loss:  7.2106576\n","Episode: 112 steps: 29\n","Episode: 113 steps: 65\n","Episode: 114 steps: 24\n","Episode: 115 steps: 29\n","Episode: 116 steps: 36\n","Episode: 117 steps: 39\n","Episode: 118 steps: 24\n","Episode: 119 steps: 22\n","Episode: 120 steps: 23\n","Episode: 121 steps: 43\n","Loss:  492.40103\n","Episode: 122 steps: 29\n","Episode: 123 steps: 42\n","Episode: 124 steps: 24\n","Episode: 125 steps: 35\n","Episode: 126 steps: 27\n","Episode: 127 steps: 31\n","Episode: 128 steps: 21\n","Episode: 129 steps: 27\n","Episode: 130 steps: 27\n","Episode: 131 steps: 18\n","Loss:  9.66687\n","Episode: 132 steps: 76\n","Episode: 133 steps: 64\n","Episode: 134 steps: 43\n","Episode: 135 steps: 40\n","Episode: 136 steps: 22\n","Episode: 137 steps: 39\n","Episode: 138 steps: 33\n","Episode: 139 steps: 42\n","Episode: 140 steps: 44\n","Episode: 141 steps: 36\n","Loss:  2.1475673\n","Episode: 142 steps: 27\n","Episode: 143 steps: 20\n","Episode: 144 steps: 26\n","Episode: 145 steps: 32\n","Episode: 146 steps: 51\n","Episode: 147 steps: 24\n","Episode: 148 steps: 23\n","Episode: 149 steps: 21\n","Episode: 150 steps: 45\n","Episode: 151 steps: 26\n","Loss:  505.53168\n","Episode: 152 steps: 15\n","Episode: 153 steps: 33\n","Episode: 154 steps: 35\n","Episode: 155 steps: 17\n","Episode: 156 steps: 20\n","Episode: 157 steps: 18\n","Episode: 158 steps: 32\n","Episode: 159 steps: 19\n","Episode: 160 steps: 16\n","Episode: 161 steps: 12\n","Loss:  2.1963654\n","Episode: 162 steps: 25\n","Episode: 163 steps: 53\n","Episode: 164 steps: 36\n","Episode: 165 steps: 24\n","Episode: 166 steps: 41\n","Episode: 167 steps: 30\n","Episode: 168 steps: 29\n","Episode: 169 steps: 26\n","Episode: 170 steps: 28\n","Episode: 171 steps: 20\n","Loss:  1.3957654\n","Episode: 172 steps: 31\n","Episode: 173 steps: 29\n","Episode: 174 steps: 20\n","Episode: 175 steps: 29\n","Episode: 176 steps: 19\n","Episode: 177 steps: 26\n","Episode: 178 steps: 32\n","Episode: 179 steps: 28\n","Episode: 180 steps: 31\n","Episode: 181 steps: 25\n","Loss:  429.51865\n","Episode: 182 steps: 25\n","Episode: 183 steps: 24\n","Episode: 184 steps: 48\n","Episode: 185 steps: 55\n","Episode: 186 steps: 70\n","Episode: 187 steps: 30\n","Episode: 188 steps: 35\n","Episode: 189 steps: 27\n","Episode: 190 steps: 56\n","Episode: 191 steps: 25\n","Loss:  980.9049\n","Episode: 192 steps: 9\n","Episode: 193 steps: 10\n","Episode: 194 steps: 10\n","Episode: 195 steps: 10\n","Episode: 196 steps: 10\n","Episode: 197 steps: 10\n","Episode: 198 steps: 10\n","Episode: 199 steps: 11\n","Episode: 200 steps: 10\n","Episode: 201 steps: 9\n","Loss:  478.44467\n","Episode: 202 steps: 43\n","Episode: 203 steps: 33\n","Episode: 204 steps: 76\n","Episode: 205 steps: 45\n","Episode: 206 steps: 26\n","Episode: 207 steps: 32\n","Episode: 208 steps: 46\n","Episode: 209 steps: 49\n","Episode: 210 steps: 29\n","Episode: 211 steps: 65\n","Loss:  3.8590455\n","Episode: 212 steps: 209\n","Episode: 213 steps: 89\n","Episode: 214 steps: 127\n","Episode: 215 steps: 70\n","Episode: 216 steps: 155\n","Episode: 217 steps: 125\n","Episode: 218 steps: 119\n","Episode: 219 steps: 117\n","Episode: 220 steps: 813\n","Episode: 221 steps: 68\n","Loss:  4.3162355\n","Episode: 222 steps: 9\n","Episode: 223 steps: 9\n","Episode: 224 steps: 9\n","Episode: 225 steps: 9\n","Episode: 226 steps: 10\n","Episode: 227 steps: 9\n","Episode: 228 steps: 8\n","Episode: 229 steps: 9\n","Episode: 230 steps: 12\n","Episode: 231 steps: 10\n","Loss:  467.8935\n","Episode: 232 steps: 68\n","Episode: 233 steps: 43\n","Episode: 234 steps: 43\n","Episode: 235 steps: 66\n","Episode: 236 steps: 40\n","Episode: 237 steps: 34\n","Episode: 238 steps: 66\n","Episode: 239 steps: 70\n","Episode: 240 steps: 47\n","Episode: 241 steps: 54\n","Loss:  1511.2543\n","Episode: 242 steps: 18\n","Episode: 243 steps: 40\n","Episode: 244 steps: 16\n","Episode: 245 steps: 17\n","Episode: 246 steps: 15\n","Episode: 247 steps: 15\n","Episode: 248 steps: 31\n","Episode: 249 steps: 15\n","Episode: 250 steps: 18\n","Episode: 251 steps: 16\n","Loss:  504.57285\n","Episode: 252 steps: 30\n","Episode: 253 steps: 24\n","Episode: 254 steps: 42\n","Episode: 255 steps: 44\n","Episode: 256 steps: 25\n","Episode: 257 steps: 29\n","Episode: 258 steps: 49\n","Episode: 259 steps: 60\n","Episode: 260 steps: 36\n","Episode: 261 steps: 40\n","Loss:  584.77106\n","Episode: 262 steps: 9\n","Episode: 263 steps: 9\n","Episode: 264 steps: 8\n","Episode: 265 steps: 9\n","Episode: 266 steps: 9\n","Episode: 267 steps: 9\n","Episode: 268 steps: 11\n","Episode: 269 steps: 9\n","Episode: 270 steps: 12\n","Episode: 271 steps: 11\n","Loss:  872.81824\n","Episode: 272 steps: 9\n","Episode: 273 steps: 9\n","Episode: 274 steps: 9\n","Episode: 275 steps: 9\n","Episode: 276 steps: 9\n","Episode: 277 steps: 10\n","Episode: 278 steps: 9\n","Episode: 279 steps: 8\n","Episode: 280 steps: 9\n","Episode: 281 steps: 9\n","Loss:  3.7535515\n","Episode: 282 steps: 26\n","Episode: 283 steps: 20\n","Episode: 284 steps: 31\n","Episode: 285 steps: 48\n","Episode: 286 steps: 20\n","Episode: 287 steps: 32\n","Episode: 288 steps: 29\n","Episode: 289 steps: 27\n","Episode: 290 steps: 43\n","Episode: 291 steps: 34\n","Loss:  2.0612254\n","Episode: 292 steps: 12\n","Episode: 293 steps: 9\n","Episode: 294 steps: 9\n","Episode: 295 steps: 9\n","Episode: 296 steps: 10\n","Episode: 297 steps: 9\n","Episode: 298 steps: 9\n","Episode: 299 steps: 9\n","Episode: 300 steps: 10\n","Episode: 301 steps: 8\n","Loss:  474.9\n","Episode: 302 steps: 32\n","Episode: 303 steps: 35\n","Episode: 304 steps: 33\n","Episode: 305 steps: 27\n","Episode: 306 steps: 41\n","Episode: 307 steps: 27\n","Episode: 308 steps: 50\n","Episode: 309 steps: 60\n","Episode: 310 steps: 58\n","Episode: 311 steps: 37\n","Loss:  9.637686\n","Episode: 312 steps: 24\n","Episode: 313 steps: 52\n","Episode: 314 steps: 27\n","Episode: 315 steps: 64\n","Episode: 316 steps: 67\n","Episode: 317 steps: 23\n","Episode: 318 steps: 21\n","Episode: 319 steps: 46\n","Episode: 320 steps: 36\n","Episode: 321 steps: 38\n","Loss:  1.411581\n","Episode: 322 steps: 154\n","Episode: 323 steps: 131\n","Episode: 324 steps: 110\n","Episode: 325 steps: 121\n","Episode: 326 steps: 95\n","Episode: 327 steps: 119\n","Episode: 328 steps: 79\n","Episode: 329 steps: 130\n","Episode: 330 steps: 105\n","Episode: 331 steps: 89\n","Loss:  518.9008\n","Episode: 332 steps: 80\n","Episode: 333 steps: 101\n","Episode: 334 steps: 92\n","Episode: 335 steps: 83\n","Episode: 336 steps: 86\n","Episode: 337 steps: 79\n","Episode: 338 steps: 80\n","Episode: 339 steps: 90\n","Episode: 340 steps: 119\n","Episode: 341 steps: 102\n","Loss:  1.8270302\n","Episode: 342 steps: 58\n","Episode: 343 steps: 44\n","Episode: 344 steps: 60\n","Episode: 345 steps: 97\n","Episode: 346 steps: 58\n","Episode: 347 steps: 47\n","Episode: 348 steps: 52\n","Episode: 349 steps: 83\n","Episode: 350 steps: 61\n","Episode: 351 steps: 61\n","Loss:  1.6199553\n","Episode: 352 steps: 11\n","Episode: 353 steps: 33\n","Episode: 354 steps: 14\n","Episode: 355 steps: 12\n","Episode: 356 steps: 19\n","Episode: 357 steps: 15\n","Episode: 358 steps: 18\n","Episode: 359 steps: 17\n","Episode: 360 steps: 15\n","Episode: 361 steps: 11\n","Loss:  0.8040085\n","Episode: 362 steps: 22\n","Episode: 363 steps: 30\n","Episode: 364 steps: 25\n","Episode: 365 steps: 25\n","Episode: 366 steps: 22\n","Episode: 367 steps: 26\n","Episode: 368 steps: 33\n","Episode: 369 steps: 22\n","Episode: 370 steps: 36\n","Episode: 371 steps: 26\n","Loss:  4.770016\n","Episode: 372 steps: 25\n","Episode: 373 steps: 19\n","Episode: 374 steps: 22\n","Episode: 375 steps: 32\n","Episode: 376 steps: 32\n","Episode: 377 steps: 34\n","Episode: 378 steps: 18\n","Episode: 379 steps: 33\n","Episode: 380 steps: 21\n","Episode: 381 steps: 26\n","Loss:  9.511836\n","Episode: 382 steps: 97\n","Episode: 383 steps: 311\n","Episode: 384 steps: 641\n","Episode: 385 steps: 340\n","Episode: 386 steps: 118\n","Episode: 387 steps: 348\n","Episode: 388 steps: 326\n","Episode: 389 steps: 203\n","Episode: 390 steps: 95\n","Episode: 391 steps: 353\n","Loss:  2.5270877\n","Episode: 392 steps: 20\n","Episode: 393 steps: 20\n","Episode: 394 steps: 28\n","Episode: 395 steps: 19\n","Episode: 396 steps: 30\n","Episode: 397 steps: 90\n","Episode: 398 steps: 23\n","Episode: 399 steps: 21\n","Episode: 400 steps: 54\n","Episode: 401 steps: 22\n","Loss:  527.26086\n","Episode: 402 steps: 250\n","Episode: 403 steps: 100\n","Episode: 404 steps: 927\n","Episode: 405 steps: 97\n","Episode: 406 steps: 416\n","Episode: 407 steps: 89\n","Episode: 408 steps: 93\n","Episode: 409 steps: 470\n","Episode: 410 steps: 85\n","Episode: 411 steps: 129\n","Loss:  6.5996895\n","Episode: 412 steps: 340\n","Episode: 413 steps: 93\n","Episode: 414 steps: 228\n","Episode: 415 steps: 76\n","Episode: 416 steps: 248\n","Episode: 417 steps: 507\n","Episode: 418 steps: 179\n","Episode: 419 steps: 1025\n","Episode: 420 steps: 215\n","Episode: 421 steps: 231\n","Loss:  4.225227\n","Episode: 422 steps: 26\n","Episode: 423 steps: 26\n","Episode: 424 steps: 37\n","Episode: 425 steps: 22\n","Episode: 426 steps: 18\n","Episode: 427 steps: 27\n","Episode: 428 steps: 25\n","Episode: 429 steps: 24\n","Episode: 430 steps: 23\n","Episode: 431 steps: 22\n","Loss:  2.787553\n","Episode: 432 steps: 17\n","Episode: 433 steps: 30\n","Episode: 434 steps: 17\n","Episode: 435 steps: 26\n","Episode: 436 steps: 22\n","Episode: 437 steps: 22\n","Episode: 438 steps: 44\n","Episode: 439 steps: 15\n","Episode: 440 steps: 41\n","Episode: 441 steps: 36\n","Loss:  2.5743277\n","Episode: 442 steps: 25\n","Episode: 443 steps: 31\n","Episode: 444 steps: 24\n","Episode: 445 steps: 25\n","Episode: 446 steps: 20\n","Episode: 447 steps: 20\n","Episode: 448 steps: 17\n","Episode: 449 steps: 23\n","Episode: 450 steps: 24\n","Episode: 451 steps: 26\n","Loss:  7.1640534\n","Episode: 452 steps: 72\n","Episode: 453 steps: 76\n","Episode: 454 steps: 46\n","Episode: 455 steps: 75\n","Episode: 456 steps: 78\n","Episode: 457 steps: 46\n","Episode: 458 steps: 63\n","Episode: 459 steps: 64\n","Episode: 460 steps: 105\n","Episode: 461 steps: 66\n","Loss:  0.70110744\n","Episode: 462 steps: 19\n","Episode: 463 steps: 24\n","Episode: 464 steps: 21\n","Episode: 465 steps: 22\n","Episode: 466 steps: 16\n","Episode: 467 steps: 26\n","Episode: 468 steps: 18\n","Episode: 469 steps: 21\n","Episode: 470 steps: 28\n","Episode: 471 steps: 22\n","Loss:  632.6348\n","Episode: 472 steps: 65\n","Episode: 473 steps: 77\n","Episode: 474 steps: 69\n","Episode: 475 steps: 57\n","Episode: 476 steps: 66\n","Episode: 477 steps: 51\n","Episode: 478 steps: 82\n","Episode: 479 steps: 51\n","Episode: 480 steps: 78\n","Episode: 481 steps: 56\n","Loss:  526.33887\n","Episode: 482 steps: 58\n","Episode: 483 steps: 23\n","Episode: 484 steps: 54\n","Episode: 485 steps: 42\n","Episode: 486 steps: 22\n","Episode: 487 steps: 40\n","Episode: 488 steps: 37\n","Episode: 489 steps: 53\n","Episode: 490 steps: 24\n","Episode: 491 steps: 20\n","Loss:  4.669343\n","Episode: 492 steps: 22\n","Episode: 493 steps: 127\n","Episode: 494 steps: 22\n","Episode: 495 steps: 29\n","Episode: 496 steps: 26\n","Episode: 497 steps: 30\n","Episode: 498 steps: 30\n","Episode: 499 steps: 30\n","Episode: 500 steps: 43\n","Episode: 501 steps: 24\n","Loss:  516.6269\n","Episode: 502 steps: 29\n","Episode: 503 steps: 30\n","Episode: 504 steps: 24\n","Episode: 505 steps: 45\n","Episode: 506 steps: 34\n","Episode: 507 steps: 28\n","Episode: 508 steps: 27\n","Episode: 509 steps: 65\n","Episode: 510 steps: 34\n","Episode: 511 steps: 24\n","Loss:  1.8239968\n","Episode: 512 steps: 21\n","Episode: 513 steps: 26\n","Episode: 514 steps: 19\n","Episode: 515 steps: 23\n","Episode: 516 steps: 25\n","Episode: 517 steps: 33\n","Episode: 518 steps: 24\n","Episode: 519 steps: 30\n","Episode: 520 steps: 28\n","Episode: 521 steps: 23\n","Loss:  5.271154\n","Episode: 522 steps: 32\n","Episode: 523 steps: 25\n","Episode: 524 steps: 25\n","Episode: 525 steps: 45\n","Episode: 526 steps: 24\n","Episode: 527 steps: 27\n","Episode: 528 steps: 33\n","Episode: 529 steps: 41\n","Episode: 530 steps: 29\n","Episode: 531 steps: 30\n","Loss:  2.4356208\n","Episode: 532 steps: 131\n","Episode: 533 steps: 171\n","Episode: 534 steps: 63\n","Episode: 535 steps: 84\n","Episode: 536 steps: 240\n","Episode: 537 steps: 86\n","Episode: 538 steps: 118\n","Episode: 539 steps: 162\n","Episode: 540 steps: 68\n","Episode: 541 steps: 72\n","Loss:  3.9590282\n","Episode: 542 steps: 213\n","Episode: 543 steps: 1289\n","Episode: 544 steps: 83\n","Episode: 545 steps: 869\n","Episode: 546 steps: 62\n","Episode: 547 steps: 155\n","Episode: 548 steps: 416\n","Episode: 549 steps: 213\n","Episode: 550 steps: 92\n","Episode: 551 steps: 129\n","Loss:  462.3531\n","Episode: 552 steps: 27\n","Episode: 553 steps: 21\n","Episode: 554 steps: 21\n","Episode: 555 steps: 21\n","Episode: 556 steps: 29\n","Episode: 557 steps: 25\n","Episode: 558 steps: 19\n","Episode: 559 steps: 25\n","Episode: 560 steps: 28\n","Episode: 561 steps: 25\n","Loss:  4.3262253\n","Episode: 562 steps: 43\n","Episode: 563 steps: 48\n","Episode: 564 steps: 74\n","Episode: 565 steps: 51\n","Episode: 566 steps: 53\n","Episode: 567 steps: 57\n","Episode: 568 steps: 39\n","Episode: 569 steps: 51\n","Episode: 570 steps: 107\n","Episode: 571 steps: 40\n","Loss:  0.6194216\n","Episode: 572 steps: 178\n","Episode: 573 steps: 95\n","Episode: 574 steps: 58\n","Episode: 575 steps: 64\n","Episode: 576 steps: 121\n","Episode: 577 steps: 102\n","Episode: 578 steps: 140\n","Episode: 579 steps: 87\n","Episode: 580 steps: 77\n","Episode: 581 steps: 284\n","Loss:  4.368992\n","Episode: 582 steps: 2511\n","Episode: 583 steps: 2097\n","Episode: 584 steps: 213\n","Episode: 585 steps: 224\n","Episode: 586 steps: 1885\n","Episode: 587 steps: 1399\n","Episode: 588 steps: 257\n","Episode: 589 steps: 580\n","Episode: 590 steps: 973\n","Episode: 591 steps: 2378\n","Loss:  0.30494508\n","Episode: 592 steps: 20\n","Episode: 593 steps: 16\n","Episode: 594 steps: 24\n","Episode: 595 steps: 20\n","Episode: 596 steps: 23\n","Episode: 597 steps: 20\n","Episode: 598 steps: 25\n","Episode: 599 steps: 28\n","Episode: 600 steps: 19\n","Episode: 601 steps: 45\n","Loss:  1.5644488\n","Episode: 602 steps: 204\n","Episode: 603 steps: 155\n","Episode: 604 steps: 114\n","Episode: 605 steps: 109\n","Episode: 606 steps: 173\n","Episode: 607 steps: 163\n","Episode: 608 steps: 120\n","Episode: 609 steps: 89\n","Episode: 610 steps: 114\n","Episode: 611 steps: 59\n","Loss:  2.1107154\n","Episode: 612 steps: 21\n","Episode: 613 steps: 21\n","Episode: 614 steps: 41\n","Episode: 615 steps: 42\n","Episode: 616 steps: 45\n","Episode: 617 steps: 39\n","Episode: 618 steps: 42\n","Episode: 619 steps: 42\n","Episode: 620 steps: 23\n","Episode: 621 steps: 23\n","Loss:  2.0474799\n","Episode: 622 steps: 25\n","Episode: 623 steps: 20\n","Episode: 624 steps: 22\n","Episode: 625 steps: 23\n","Episode: 626 steps: 18\n","Episode: 627 steps: 15\n","Episode: 628 steps: 16\n","Episode: 629 steps: 20\n","Episode: 630 steps: 22\n","Episode: 631 steps: 19\n","Loss:  2.3186612\n","Episode: 632 steps: 28\n","Episode: 633 steps: 25\n","Episode: 634 steps: 25\n","Episode: 635 steps: 21\n","Episode: 636 steps: 19\n","Episode: 637 steps: 27\n","Episode: 638 steps: 31\n","Episode: 639 steps: 19\n","Episode: 640 steps: 21\n","Episode: 641 steps: 16\n","Loss:  5.3125143\n","Episode: 642 steps: 25\n","Episode: 643 steps: 23\n","Episode: 644 steps: 41\n","Episode: 645 steps: 35\n","Episode: 646 steps: 24\n","Episode: 647 steps: 20\n","Episode: 648 steps: 22\n","Episode: 649 steps: 27\n","Episode: 650 steps: 42\n","Episode: 651 steps: 22\n","Loss:  1.5302635\n","Episode: 652 steps: 24\n","Episode: 653 steps: 26\n","Episode: 654 steps: 31\n","Episode: 655 steps: 26\n","Episode: 656 steps: 21\n","Episode: 657 steps: 29\n","Episode: 658 steps: 24\n","Episode: 659 steps: 23\n","Episode: 660 steps: 22\n","Episode: 661 steps: 26\n","Loss:  495.53354\n","Episode: 662 steps: 8\n","Episode: 663 steps: 8\n","Episode: 664 steps: 10\n","Episode: 665 steps: 9\n","Episode: 666 steps: 9\n","Episode: 667 steps: 9\n","Episode: 668 steps: 10\n","Episode: 669 steps: 9\n","Episode: 670 steps: 8\n","Episode: 671 steps: 9\n","Loss:  2.750694\n","Episode: 672 steps: 23\n","Episode: 673 steps: 53\n","Episode: 674 steps: 55\n","Episode: 675 steps: 38\n","Episode: 676 steps: 28\n","Episode: 677 steps: 37\n","Episode: 678 steps: 39\n","Episode: 679 steps: 26\n","Episode: 680 steps: 30\n","Episode: 681 steps: 36\n","Loss:  1.5371358\n","Episode: 682 steps: 29\n","Episode: 683 steps: 26\n","Episode: 684 steps: 23\n","Episode: 685 steps: 34\n","Episode: 686 steps: 43\n","Episode: 687 steps: 27\n","Episode: 688 steps: 26\n","Episode: 689 steps: 21\n","Episode: 690 steps: 22\n","Episode: 691 steps: 25\n","Loss:  462.92563\n","Episode: 692 steps: 146\n","Episode: 693 steps: 107\n","Episode: 694 steps: 172\n","Episode: 695 steps: 388\n","Episode: 696 steps: 518\n","Episode: 697 steps: 237\n","Episode: 698 steps: 285\n","Episode: 699 steps: 365\n","Episode: 700 steps: 277\n","Episode: 701 steps: 341\n","Loss:  1.8570083\n","Episode: 702 steps: 53\n","Episode: 703 steps: 28\n","Episode: 704 steps: 22\n","Episode: 705 steps: 25\n","Episode: 706 steps: 24\n","Episode: 707 steps: 26\n","Episode: 708 steps: 21\n","Episode: 709 steps: 41\n","Episode: 710 steps: 62\n","Episode: 711 steps: 56\n","Loss:  420.29492\n","Episode: 712 steps: 10\n","Episode: 713 steps: 9\n","Episode: 714 steps: 9\n","Episode: 715 steps: 8\n","Episode: 716 steps: 9\n","Episode: 717 steps: 9\n","Episode: 718 steps: 9\n","Episode: 719 steps: 9\n","Episode: 720 steps: 9\n","Episode: 721 steps: 8\n","Loss:  1.385628\n","Episode: 722 steps: 65\n","Episode: 723 steps: 38\n","Episode: 724 steps: 97\n","Episode: 725 steps: 38\n","Episode: 726 steps: 80\n","Episode: 727 steps: 46\n","Episode: 728 steps: 30\n","Episode: 729 steps: 24\n","Episode: 730 steps: 20\n","Episode: 731 steps: 26\n","Loss:  0.89787847\n","Episode: 732 steps: 54\n","Episode: 733 steps: 37\n","Episode: 734 steps: 36\n","Episode: 735 steps: 31\n","Episode: 736 steps: 26\n","Episode: 737 steps: 38\n","Episode: 738 steps: 52\n","Episode: 739 steps: 28\n","Episode: 740 steps: 44\n","Episode: 741 steps: 34\n","Loss:  1.8221099\n","Episode: 742 steps: 22\n","Episode: 743 steps: 23\n","Episode: 744 steps: 40\n","Episode: 745 steps: 25\n","Episode: 746 steps: 24\n","Episode: 747 steps: 57\n","Episode: 748 steps: 22\n","Episode: 749 steps: 24\n","Episode: 750 steps: 22\n","Episode: 751 steps: 22\n","Loss:  8.594261\n","Episode: 752 steps: 38\n","Episode: 753 steps: 45\n","Episode: 754 steps: 39\n","Episode: 755 steps: 46\n","Episode: 756 steps: 38\n","Episode: 757 steps: 33\n","Episode: 758 steps: 50\n","Episode: 759 steps: 30\n","Episode: 760 steps: 48\n","Episode: 761 steps: 63\n","Loss:  1.0694447\n","Episode: 762 steps: 53\n","Episode: 763 steps: 56\n","Episode: 764 steps: 58\n","Episode: 765 steps: 73\n","Episode: 766 steps: 56\n","Episode: 767 steps: 44\n","Episode: 768 steps: 47\n","Episode: 769 steps: 76\n","Episode: 770 steps: 58\n","Episode: 771 steps: 60\n","Loss:  531.7559\n","Episode: 772 steps: 99\n","Episode: 773 steps: 55\n","Episode: 774 steps: 120\n","Episode: 775 steps: 119\n","Episode: 776 steps: 114\n","Episode: 777 steps: 160\n","Episode: 778 steps: 117\n","Episode: 779 steps: 102\n","Episode: 780 steps: 167\n","Episode: 781 steps: 70\n","Loss:  510.46713\n","Episode: 782 steps: 61\n","Episode: 783 steps: 88\n","Episode: 784 steps: 47\n","Episode: 785 steps: 67\n","Episode: 786 steps: 79\n","Episode: 787 steps: 56\n","Episode: 788 steps: 81\n","Episode: 789 steps: 74\n","Episode: 790 steps: 59\n","Episode: 791 steps: 83\n","Loss:  8.906191\n","Episode: 792 steps: 26\n","Episode: 793 steps: 47\n","Episode: 794 steps: 42\n","Episode: 795 steps: 37\n","Episode: 796 steps: 28\n","Episode: 797 steps: 67\n","Episode: 798 steps: 33\n","Episode: 799 steps: 39\n","Episode: 800 steps: 70\n","Episode: 801 steps: 44\n","Loss:  5.128512\n","Episode: 802 steps: 36\n","Episode: 803 steps: 25\n","Episode: 804 steps: 33\n","Episode: 805 steps: 24\n","Episode: 806 steps: 25\n","Episode: 807 steps: 25\n","Episode: 808 steps: 32\n","Episode: 809 steps: 66\n","Episode: 810 steps: 28\n","Episode: 811 steps: 29\n","Loss:  1.8061745\n","Episode: 812 steps: 49\n","Episode: 813 steps: 64\n","Episode: 814 steps: 77\n","Episode: 815 steps: 48\n","Episode: 816 steps: 72\n","Episode: 817 steps: 61\n","Episode: 818 steps: 49\n","Episode: 819 steps: 84\n","Episode: 820 steps: 51\n","Episode: 821 steps: 83\n","Loss:  4.64006\n","Episode: 822 steps: 22\n","Episode: 823 steps: 23\n","Episode: 824 steps: 21\n","Episode: 825 steps: 22\n","Episode: 826 steps: 36\n","Episode: 827 steps: 60\n","Episode: 828 steps: 65\n","Episode: 829 steps: 45\n","Episode: 830 steps: 20\n","Episode: 831 steps: 22\n","Loss:  4.8589067\n","Episode: 832 steps: 30\n","Episode: 833 steps: 33\n","Episode: 834 steps: 56\n","Episode: 835 steps: 42\n","Episode: 836 steps: 40\n","Episode: 837 steps: 40\n","Episode: 838 steps: 31\n","Episode: 839 steps: 26\n","Episode: 840 steps: 47\n","Episode: 841 steps: 59\n","Loss:  2.4153762\n","Episode: 842 steps: 31\n","Episode: 843 steps: 25\n","Episode: 844 steps: 11\n","Episode: 845 steps: 9\n","Episode: 846 steps: 25\n","Episode: 847 steps: 17\n","Episode: 848 steps: 13\n","Episode: 849 steps: 19\n","Episode: 850 steps: 16\n","Episode: 851 steps: 19\n","Loss:  1.4819072\n","Episode: 852 steps: 47\n","Episode: 853 steps: 34\n","Episode: 854 steps: 22\n","Episode: 855 steps: 23\n","Episode: 856 steps: 24\n","Episode: 857 steps: 29\n","Episode: 858 steps: 30\n","Episode: 859 steps: 57\n","Episode: 860 steps: 23\n","Episode: 861 steps: 23\n","Loss:  1.2722979\n","Episode: 862 steps: 166\n","Episode: 863 steps: 134\n","Episode: 864 steps: 54\n","Episode: 865 steps: 120\n","Episode: 866 steps: 66\n","Episode: 867 steps: 136\n","Episode: 868 steps: 51\n","Episode: 869 steps: 50\n","Episode: 870 steps: 95\n","Episode: 871 steps: 112\n","Loss:  1.113455\n","Episode: 872 steps: 21\n","Episode: 873 steps: 120\n","Episode: 874 steps: 20\n","Episode: 875 steps: 22\n","Episode: 876 steps: 43\n","Episode: 877 steps: 59\n","Episode: 878 steps: 26\n","Episode: 879 steps: 35\n","Episode: 880 steps: 22\n","Episode: 881 steps: 49\n","Loss:  7.168143\n","Episode: 882 steps: 101\n","Episode: 883 steps: 75\n","Episode: 884 steps: 111\n","Episode: 885 steps: 79\n","Episode: 886 steps: 75\n","Episode: 887 steps: 124\n","Episode: 888 steps: 77\n","Episode: 889 steps: 63\n","Episode: 890 steps: 79\n","Episode: 891 steps: 77\n","Loss:  1.0655763\n","Episode: 892 steps: 10\n","Episode: 893 steps: 19\n","Episode: 894 steps: 14\n","Episode: 895 steps: 9\n","Episode: 896 steps: 52\n","Episode: 897 steps: 10\n","Episode: 898 steps: 19\n","Episode: 899 steps: 13\n","Episode: 900 steps: 12\n","Episode: 901 steps: 8\n","Loss:  2.9766746\n","Episode: 902 steps: 40\n","Episode: 903 steps: 26\n","Episode: 904 steps: 30\n","Episode: 905 steps: 25\n","Episode: 906 steps: 44\n","Episode: 907 steps: 35\n","Episode: 908 steps: 25\n","Episode: 909 steps: 23\n","Episode: 910 steps: 33\n","Episode: 911 steps: 24\n","Loss:  3.554919\n","Episode: 912 steps: 30\n","Episode: 913 steps: 23\n","Episode: 914 steps: 22\n","Episode: 915 steps: 24\n","Episode: 916 steps: 25\n","Episode: 917 steps: 25\n","Episode: 918 steps: 37\n","Episode: 919 steps: 39\n","Episode: 920 steps: 26\n","Episode: 921 steps: 24\n","Loss:  3.3763962\n","Episode: 922 steps: 10001\n","Total score: 10001.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]}]}