{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import gym      # environment 라이브러리\r\n",
    "from reinforce import *\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from torch.distributions import Categorical"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def main():\r\n",
    "    # environment를 생성한다. \r\n",
    "    env = gym.make('CartPole-v1')\r\n",
    "    # Policy 클래스의 인스턴스를 생성한다.\r\n",
    "    pi = Policy()\r\n",
    "    score = 0.0\r\n",
    "    print_interval = 20\r\n",
    "\r\n",
    "    # episode를 만 번 시뮬레이션 한다.\r\n",
    "    for n_epi in range(10000):\r\n",
    "        # env를 처음 상태로 초기화함과 동시에 observation 결과, 즉 state를 돌려준다.\r\n",
    "        # CartPole의 경우 state는 네 개의 실수로 구성되어 있다. \r\n",
    "        # CartPole 환경의 자세한 사항은 https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py 에서 확인.\r\n",
    "        s = env.reset()\r\n",
    "        done = False\r\n",
    "\r\n",
    "        while not done:\r\n",
    "            # numpy.ndarray인 s를 tensor로 바꿔서 policy input으로 넣어준다. 그럼 output으로 확률분포를 얻는다. \r\n",
    "            # CartPole의 경우 action이 2개이다. 왼쪽으로 밀기, 오른쪽으로 밀기\r\n",
    "            # 예를 들어 (왼쪽으로 밀 확률 0.8, 오른쪽으로 밀 확률 0.2) 와 같이 확률 분포가 주어진다.\r\n",
    "            prob = pi(torch.from_numpy(s).float())\r\n",
    "            # policy가 stochastic policy이므로 sampling을 해야 한다.\r\n",
    "            # pytorch의 Categorical은 확률분포 모델이다.\r\n",
    "            m = Categorical(prob)\r\n",
    "            # 이 모델에서 sample을 호출하면 확률분포에 맞게 action을 tensor로 뽑아준다.\r\n",
    "            a = m.sample()\r\n",
    "            # env.step에 action을 주면 그 결과의 observation을 얻는다. =state transition\r\n",
    "            # a.item()은 tensor에서 scalar를 추출하기 위해 호출한 것이다.\r\n",
    "            s_prime, r, done, info = env.step(a.item())\r\n",
    "            # REINFORCE 알고리즘은 return이 필요하기 때문에 에피소드가 끝나야 학습할 수 있다.\r\n",
    "            # for 문을 돌면서 얻는 경험을 policy에 쌓아두기만 한다.\r\n",
    "            # (현재 reward, 현재 action을 선택할 확률)\r\n",
    "            pi.put_data((r, prob[a]))\r\n",
    "            s = s_prime\r\n",
    "            # score는 reward의 누적인데, reward는 매 스텝을 버틸 때마다 +1이 주어진다.\r\n",
    "            score += r\r\n",
    "\r\n",
    "        # 에피소드가 종료되었으므로 학습시킨다.\r\n",
    "        pi.train_net()\r\n",
    "\r\n",
    "        if n_epi % print_interval == 0 and n_epi != 0:\r\n",
    "            # 20 에피소드 평균 score를 출력함.\r\n",
    "            print(f\"# of epi: {n_epi}, avg score: {score/print_interval}\")\r\n",
    "            score = 0.0\r\n",
    "    env.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "if __name__ == '__main__':\r\n",
    "    main()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# of epi: 20, avg score: 20.5\n",
      "# of epi: 40, avg score: 29.15\n",
      "# of epi: 60, avg score: 27.85\n",
      "# of epi: 80, avg score: 27.45\n",
      "# of epi: 100, avg score: 40.15\n",
      "# of epi: 120, avg score: 28.95\n",
      "# of epi: 140, avg score: 38.45\n",
      "# of epi: 160, avg score: 43.25\n",
      "# of epi: 180, avg score: 41.7\n",
      "# of epi: 200, avg score: 36.7\n",
      "# of epi: 220, avg score: 46.7\n",
      "# of epi: 240, avg score: 44.05\n",
      "# of epi: 260, avg score: 49.75\n",
      "# of epi: 280, avg score: 56.6\n",
      "# of epi: 300, avg score: 63.15\n",
      "# of epi: 320, avg score: 65.7\n",
      "# of epi: 340, avg score: 45.4\n",
      "# of epi: 360, avg score: 76.85\n",
      "# of epi: 380, avg score: 76.5\n",
      "# of epi: 400, avg score: 62.4\n",
      "# of epi: 420, avg score: 120.7\n",
      "# of epi: 440, avg score: 84.75\n",
      "# of epi: 460, avg score: 123.0\n",
      "# of epi: 480, avg score: 128.1\n",
      "# of epi: 500, avg score: 138.95\n",
      "# of epi: 520, avg score: 162.45\n",
      "# of epi: 540, avg score: 166.3\n",
      "# of epi: 560, avg score: 116.75\n",
      "# of epi: 580, avg score: 149.6\n",
      "# of epi: 600, avg score: 149.55\n",
      "# of epi: 620, avg score: 163.55\n",
      "# of epi: 640, avg score: 209.3\n",
      "# of epi: 660, avg score: 206.4\n",
      "# of epi: 680, avg score: 241.95\n",
      "# of epi: 700, avg score: 242.5\n",
      "# of epi: 720, avg score: 280.9\n",
      "# of epi: 740, avg score: 282.55\n",
      "# of epi: 760, avg score: 293.15\n",
      "# of epi: 780, avg score: 357.25\n",
      "# of epi: 800, avg score: 249.4\n",
      "# of epi: 820, avg score: 223.1\n",
      "# of epi: 840, avg score: 213.45\n",
      "# of epi: 860, avg score: 282.1\n",
      "# of epi: 880, avg score: 300.2\n",
      "# of epi: 900, avg score: 324.8\n",
      "# of epi: 920, avg score: 262.6\n",
      "# of epi: 940, avg score: 186.1\n",
      "# of epi: 960, avg score: 198.95\n",
      "# of epi: 980, avg score: 206.7\n",
      "# of epi: 1000, avg score: 331.8\n",
      "# of epi: 1020, avg score: 319.25\n",
      "# of epi: 1040, avg score: 302.3\n",
      "# of epi: 1060, avg score: 292.5\n",
      "# of epi: 1080, avg score: 338.05\n",
      "# of epi: 1100, avg score: 384.85\n",
      "# of epi: 1120, avg score: 350.1\n",
      "# of epi: 1140, avg score: 375.8\n",
      "# of epi: 1160, avg score: 357.8\n",
      "# of epi: 1180, avg score: 357.9\n",
      "# of epi: 1200, avg score: 352.95\n",
      "# of epi: 1220, avg score: 334.5\n",
      "# of epi: 1240, avg score: 266.45\n",
      "# of epi: 1260, avg score: 262.4\n",
      "# of epi: 1280, avg score: 366.2\n",
      "# of epi: 1300, avg score: 368.8\n",
      "# of epi: 1320, avg score: 408.05\n",
      "# of epi: 1340, avg score: 431.05\n",
      "# of epi: 1360, avg score: 356.35\n",
      "# of epi: 1380, avg score: 355.6\n",
      "# of epi: 1400, avg score: 338.45\n",
      "# of epi: 1420, avg score: 407.55\n",
      "# of epi: 1440, avg score: 417.05\n",
      "# of epi: 1460, avg score: 391.2\n",
      "# of epi: 1480, avg score: 376.75\n",
      "# of epi: 1500, avg score: 378.65\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28460/4096478566.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28460/3394386687.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;31m# policy가 stochastic policy이므로 sampling을 해야 한다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;31m# pytorch의 Categorical은 확률분포 모델이다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[1;31m# 이 모델에서 sample을 호출하면 확률분포에 맞게 action을 tensor로 뽑아준다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38-pytorch-gpu\\lib\\site-packages\\torch\\distributions\\categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, probs, logits, validate_args)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_events\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mbatch_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_param\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38-pytorch-gpu\\lib\\site-packages\\torch\\distributions\\distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__dict__\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy_property\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m                     \u001b[1;32mcontinue\u001b[0m  \u001b[1;31m# skip checking lazily-constructed args\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The parameter {} has invalid values\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py38-pytorch-gpu\\lib\\site-packages\\torch\\distributions\\constraints.py\u001b[0m in \u001b[0;36mcheck\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 399\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('py38-pytorch-gpu': conda)"
  },
  "interpreter": {
   "hash": "92bb61e8f2b0dcdaa21cd71aad1d97e3da046ad8a677ac321cbd25d595832889"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}