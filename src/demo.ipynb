{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrun tensorboard server\\n\\nconda activate py38-pytorch-gpu && tensorboard --port=6006 --logdir=runs\\nhttp://localhost:6006/\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "run anaconda prompt \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "home_path = os.path.expanduser('~')\n",
    "cur_path = os.getcwd()\n",
    "conda_path = home_path + \"\\\\anaconda3\"\n",
    "conda_script_path = home_path + \"\\\\anaconda3\\\\Scripts\\\\activate.bat\"\n",
    "exc = ' '.join(['start', '%windir%\\System32\\cmd.exe \"/K\"', conda_script_path, conda_path])\n",
    "!$exc\n",
    "\n",
    "\"\"\"\n",
    "run tensorboard server\n",
    "\n",
    "conda activate py38-pytorch-gpu && tensorboard --port=6006 --logdir=runs\n",
    "http://localhost:6006/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[ LunarLander-v2, <class 'algorithms.ddqn_runner.DDQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kuro1\\anaconda3\\envs\\py38-pytorch-gpu\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] 스레드 모드가 설정된 후에는 바꿀 수 없습니다\n",
      "  warnings.warn(str(err))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_epi=0, self._score=263.8903887868929 비디오 저장\n",
      "에피소드: 0, 점수: 263.9\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=193.6919576506781 비디오 저장\n",
      "에피소드: 1, 점수: 193.7\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=-109.46198652880487 비디오 저장\n",
      "에피소드: 2, 점수: -109.5\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 -109.46198652880487\n",
      "\t[ LunarLander-v2, <class 'algorithms.ddqn_runner.DDQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=-72.45436516243974 비디오 저장\n",
      "에피소드: 0, 점수: -72.5\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=-103.0918409131749 비디오 저장\n",
      "에피소드: 1, 점수: -103.1\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=-116.72847071341423 비디오 저장\n",
      "에피소드: 2, 점수: -116.7\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 -116.72847071341423\n",
      "\t[ LunarLander-v2, <class 'algorithms.ddqn_runner.DDQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=-63.32367347344572 비디오 저장\n",
      "에피소드: 0, 점수: -63.3\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=-51.674739587618795 비디오 저장\n",
      "에피소드: 1, 점수: -51.7\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=-72.12799525588198 비디오 저장\n",
      "에피소드: 2, 점수: -72.1\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 -72.12799525588198\n",
      "\t[ LunarLander-v2, <class 'algorithms.ddqn_runner.DDQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=-18.85419337755374 비디오 저장\n",
      "에피소드: 0, 점수: -18.9\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=186.25627410211314 비디오 저장\n",
      "에피소드: 1, 점수: 186.3\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=176.58410607232872 비디오 저장\n",
      "에피소드: 2, 점수: 176.6\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 176.58410607232872\n",
      "\t[ LunarLander-v2, <class 'algorithms.ddqn_runner.DDQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=-117.80007095343964 비디오 저장\n",
      "에피소드: 0, 점수: -117.8\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=-236.25904472799203 비디오 저장\n",
      "에피소드: 1, 점수: -236.3\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=-168.71814154734375 비디오 저장\n",
      "에피소드: 2, 점수: -168.7\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 -168.71814154734375\n",
      "\t[ LunarLander-v2, <class 'algorithms.ddqn_runner.DDQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=155.28946789426652 비디오 저장\n",
      "에피소드: 0, 점수: 155.3\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=-57.77997884025504 비디오 저장\n",
      "에피소드: 1, 점수: -57.8\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=147.45863137732857 비디오 저장\n",
      "에피소드: 2, 점수: 147.5\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 147.45863137732857\n",
      "\t[ LunarLander-v2, <class 'algorithms.ddqn_runner.DDQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=70.56933867851397 비디오 저장\n",
      "에피소드: 0, 점수: 70.6\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=129.15638922704 비디오 저장\n",
      "에피소드: 1, 점수: 129.2\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=130.19992056202994 비디오 저장\n",
      "에피소드: 2, 점수: 130.2\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 130.19992056202994\n",
      "\t[ LunarLander-v2, <class 'algorithms.ddqn_runner.DDQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=263.76396210202654 비디오 저장\n",
      "에피소드: 0, 점수: 263.8\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=226.89174161200185 비디오 저장\n",
      "에피소드: 1, 점수: 226.9\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=199.6384695213053 비디오 저장\n",
      "에피소드: 2, 점수: 199.6\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 199.6384695213053\n",
      "\t[ LunarLander-v2, <class 'algorithms.ddqn_runner.DDQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=188.89274950959103 비디오 저장\n",
      "에피소드: 0, 점수: 188.9\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=133.05737212898208 비디오 저장\n",
      "에피소드: 1, 점수: 133.1\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=207.50293037381513 비디오 저장\n",
      "에피소드: 2, 점수: 207.5\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 207.50293037381513\n",
      "\t[ LunarLander-v2, <class 'algorithms.ddqn_runner.DDQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=-80.89418235802924 비디오 저장\n",
      "에피소드: 0, 점수: -80.9\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=291.55764277103924 비디오 저장\n",
      "에피소드: 1, 점수: 291.6\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=-20.178039643696106 비디오 저장\n",
      "에피소드: 2, 점수: -20.2\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 -20.178039643696106\n",
      "\t[ LunarLander-v2, <class 'algorithms.dqn_runner.DQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=247.4784790152117 비디오 저장\n",
      "에피소드: 0, 점수: 247.5\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=267.32096238073484 비디오 저장\n",
      "에피소드: 1, 점수: 267.3\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=3.704863065553389 비디오 저장\n",
      "에피소드: 2, 점수: 3.7\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 3.704863065553389\n",
      "\t[ LunarLander-v2, <class 'algorithms.dqn_runner.DQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=193.99231340887425 비디오 저장\n",
      "에피소드: 0, 점수: 194.0\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=210.94395746304875 비디오 저장\n",
      "에피소드: 1, 점수: 210.9\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=192.95041779772959 비디오 저장\n",
      "에피소드: 2, 점수: 193.0\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 192.95041779772959\n",
      "\t[ LunarLander-v2, <class 'algorithms.dqn_runner.DQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=-21.178304380449614 비디오 저장\n",
      "에피소드: 0, 점수: -21.2\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=4.265006263535451 비디오 저장\n",
      "에피소드: 1, 점수: 4.3\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=161.6244632604799 비디오 저장\n",
      "에피소드: 2, 점수: 161.6\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 161.6244632604799\n",
      "\t[ LunarLander-v2, <class 'algorithms.dqn_runner.DQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=262.97785117395136 비디오 저장\n",
      "에피소드: 0, 점수: 263.0\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=15.16103091969958 비디오 저장\n",
      "에피소드: 1, 점수: 15.2\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=260.67298030157417 비디오 저장\n",
      "에피소드: 2, 점수: 260.7\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 260.67298030157417\n",
      "\t[ LunarLander-v2, <class 'algorithms.dqn_runner.DQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=-62.80134803644194 비디오 저장\n",
      "에피소드: 0, 점수: -62.8\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=-81.97316476617226 비디오 저장\n",
      "에피소드: 1, 점수: -82.0\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=-168.57662598029057 비디오 저장\n",
      "에피소드: 2, 점수: -168.6\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 -168.57662598029057\n",
      "\t[ LunarLander-v2, <class 'algorithms.dqn_runner.DQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=131.00003525957726 비디오 저장\n",
      "에피소드: 0, 점수: 131.0\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=217.54843965212063 비디오 저장\n",
      "에피소드: 1, 점수: 217.5\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=5.938667479044398 비디오 저장\n",
      "에피소드: 2, 점수: 5.9\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 5.938667479044398\n",
      "\t[ LunarLander-v2, <class 'algorithms.dqn_runner.DQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=-37.76731354373686 비디오 저장\n",
      "에피소드: 0, 점수: -37.8\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=256.90881302604873 비디오 저장\n",
      "에피소드: 1, 점수: 256.9\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=278.33938070728794 비디오 저장\n",
      "에피소드: 2, 점수: 278.3\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 278.33938070728794\n",
      "\t[ LunarLander-v2, <class 'algorithms.dqn_runner.DQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=256.6526361168976 비디오 저장\n",
      "에피소드: 0, 점수: 256.7\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=262.1720985197463 비디오 저장\n",
      "에피소드: 1, 점수: 262.2\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=200.65415988972086 비디오 저장\n",
      "에피소드: 2, 점수: 200.7\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 200.65415988972086\n",
      "\t[ LunarLander-v2, <class 'algorithms.dqn_runner.DQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=254.0937077238129 비디오 저장\n",
      "에피소드: 0, 점수: 254.1\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=1, self._score=255.35717468169412 비디오 저장\n",
      "에피소드: 1, 점수: 255.4\n",
      "n_buffer : 0, eps : 0.0%\n",
      "n_epi=2, self._score=193.54420387380182 비디오 저장\n",
      "에피소드: 2, 점수: 193.5\n",
      "n_buffer : 0, eps : 0.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 193.54420387380182\n",
      "\t[ LunarLander-v2, <class 'algorithms.dqn_runner.DQNRunner'> ]\n",
      " parameters dict_items([('n_node', 128), ('learning_rate', 0.0025), ('gamma', 0.98), ('buffer_limit', 100000), ('batch_size', 64), ('n_train_start', 10000), ('update_interval', 20)])\n",
      "\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from manifest import Manifest\n",
    "from logger import Logger\n",
    "from remover import Remover\n",
    "\n",
    "# 자동완성용 import\n",
    "from env import Env\n",
    "from runner import RunnerParams\n",
    "from trainer import Trainer\n",
    "from player import Player\n",
    "\n",
    "from algorithms.dqn import DQN, DQNParams\n",
    "from algorithms.dqn_runner import DQNRunner\n",
    "from algorithms.ddqn import DDQN, DDQNParams\n",
    "from algorithms.ddqn_runner import DDQNRunner\n",
    "from algorithms.reinforce import Reinforce, ReinforceParams\n",
    "from algorithms.reinforce_runner import ReinforceRunner\n",
    "from algorithms.actorcritic import ActorCritic, ActorCriticParams\n",
    "from algorithms.actorcritic_runner import ActorCriticRunner\n",
    "\n",
    "\n",
    "import collections\n",
    "\n",
    "def train():\n",
    "    cases = Trainer().allcases\n",
    "    cartpole_cases = filter(lambda x:x[0] == Env.CARTPOLE, cases)\n",
    "    lunar_cases = filter(lambda x:x[0] == Env.LUNARLANDER, cases)\n",
    "\n",
    "    check_interval_arr = [5]\n",
    "    tr = Trainer(check_interval_arr)\n",
    "    for env, algo in lunar_cases:\n",
    "        tr.add_case(env, algo)\n",
    "    tr.run()\n",
    "    \n",
    "    check_interval_arr = [10]\n",
    "    tr = Trainer(check_interval_arr)\n",
    "    for env, algo in cartpole_cases:\n",
    "        tr.add_case(env, algo)\n",
    "    tr.run()\n",
    "    \n",
    "\n",
    "def play():\n",
    "    PATH = os.path.join(os.getcwd(), 'weights')\n",
    "    filenames = ['.'.join(tokens[:-1]) \n",
    "                        for name in os.listdir(PATH) \n",
    "                        if (tokens := name.split('.')) and len(tokens) > 2]\n",
    "\n",
    "    # Player('weights', filenames).run(runner_param_dic={'max_episode': 125})\n",
    "    Player('weights', filenames).run(debug=True)\n",
    "\n",
    "\n",
    "def train_dqn_ddqn():\n",
    "    cases = Trainer().allcases\n",
    "    target_cases = filter(lambda x:(x[1] == DQN) or (x[1] == DDQN), cases)\n",
    "    cartpole_cases = filter(lambda x:x[0] == Env.CARTPOLE, target_cases)\n",
    "    lunar_cases = filter(lambda x:x[0] == Env.LUNARLANDER, target_cases)\n",
    "\n",
    "    check_interval_arr = [5]\n",
    "    tr = Trainer(check_interval_arr)\n",
    "    for env, algo in lunar_cases:\n",
    "        tr.add_case(env, algo)\n",
    "    tr.run()\n",
    "    \n",
    "    # check_interval_arr = [10]\n",
    "    # tr = Trainer(check_interval_arr)\n",
    "    # for env, algo in cartpole_cases:\n",
    "    #     tr.add_case(env, algo)\n",
    "    # tr.run()\n",
    "\n",
    "\n",
    "# Remover().remove_dirs(['runs', 'weights', 'videos'])\n",
    "# Remover().remove_dirs(['logs'])\n",
    "\n",
    "# for i in range(10):\n",
    "#     train()\n",
    "\n",
    "# print_interval=10, max_epi=100 > 4분 35초\n",
    "# print_interval=0, max_epi=100 > 4분 25초\n",
    "# save_check_log=True, print_interval=0, max_epi=100 > 4분 37초\n",
    "\n",
    "play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_reinforce():\n",
    "    tr = Trainer([10])\n",
    "    for env, algo in [(Env.LUNARLANDER, Reinforce)]:\n",
    "        start = 5\n",
    "        k = 5\n",
    "        for i in range(21):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.learning_rate = (start + k*i)/10000\n",
    "            tr.add_case(env, algo, hparam)\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "def tuning_actorcritic():\n",
    "    tr = Trainer([10])\n",
    "    for env, algo in [(Env.LUNARLANDER, ActorCritic)]:\n",
    "        start = 1\n",
    "        k = 5\n",
    "        for i in range(21):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.learning_rate = (start + k*i)/10000\n",
    "            tr.add_case(env, algo, hparam)\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "def tuning_dqn_node_cartpole():\n",
    "    \"\"\"\n",
    "    8\n",
    "    \"\"\"\n",
    "    tr = Trainer([20])\n",
    "    for env, algo in [(Env.CARTPOLE, DQN)]:\n",
    "        n_node = 2\n",
    "        for i in range(8):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.n_node = n_node\n",
    "            tr.add_case(env, algo, hparam)\n",
    "            n_node *= 2\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "def tuning_dqn_node_lunarlander():\n",
    "    \"\"\"\n",
    "    64~256\n",
    "    \"\"\"\n",
    "    tr = Trainer([10])\n",
    "    for env, algo in [(Env.LUNARLANDER, DQN)]:\n",
    "        n_node = 2\n",
    "        for i in range(8):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.n_node = n_node\n",
    "            tr.add_case(env, algo, hparam)\n",
    "            n_node *= 2\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "def tuning_ddqn_node_cartpole():\n",
    "    \"\"\"\n",
    "    8~16\n",
    "    \"\"\"\n",
    "    tr = Trainer([20])\n",
    "    for env, algo in [(Env.CARTPOLE, DDQN)]:\n",
    "        n_node = 64\n",
    "        for i in range(2):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.n_node = n_node\n",
    "            tr.add_case(env, algo, hparam)\n",
    "            n_node *= 2\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "def tuning_ddqn_node_lunarlander():\n",
    "    \"\"\"\n",
    "    32, 128, 256\n",
    "    \"\"\"\n",
    "    tr = Trainer([10])\n",
    "    for env, algo in [(Env.LUNARLANDER, DDQN)]:\n",
    "        n_node = 32\n",
    "        for i in range(4):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.n_node = n_node\n",
    "            tr.add_case(env, algo, hparam)\n",
    "            n_node *= 2\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "# Remover().remove_dirs(['runs', 'weights', 'videos'])\n",
    "# tuning_dqn_node_cartpole()\n",
    "# tuning_dqn_node_lunarlander()\n",
    "tuning_ddqn_node_lunarlander()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92bb61e8f2b0dcdaa21cd71aad1d97e3da046ad8a677ac321cbd25d595832889"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('py38-pytorch-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
