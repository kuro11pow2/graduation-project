{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrun tensorboard server\\n\\nconda activate py38-pytorch-gpu && tensorboard --port=6006 --logdir=runs\\nhttp://localhost:6006/\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "run anaconda prompt \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "home_path = os.path.expanduser('~')\n",
    "cur_path = os.getcwd()\n",
    "conda_path = home_path + \"\\\\anaconda3\"\n",
    "conda_script_path = home_path + \"\\\\anaconda3\\\\Scripts\\\\activate.bat\"\n",
    "exc = ' '.join(['start', '%windir%\\System32\\cmd.exe \"/K\"', conda_script_path, conda_path])\n",
    "!$exc\n",
    "\n",
    "\"\"\"\n",
    "run tensorboard server\n",
    "\n",
    "conda activate py38-pytorch-gpu && tensorboard --port=6006 --logdir=runs\n",
    "http://localhost:6006/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import Env\n",
    "from runner import RunnerParams\n",
    "from logger import Logger\n",
    "from remover import Remover\n",
    "from algorithms.dqn import DQN, DQNParams\n",
    "from algorithms.dqn_runner import DQNRunner\n",
    "from algorithms.ddqn import DDQN, DDQNParams\n",
    "from algorithms.ddqn_runner import DDQNRunner\n",
    "from algorithms.reinforce import Reinforce, ReinforceParams\n",
    "from algorithms.reinforce_runner import ReinforceRunner\n",
    "from algorithms.actorcritic import ActorCritic, ActorCriticParams\n",
    "from algorithms.actorcritic_runner import ActorCriticRunner\n",
    "\n",
    "import itertools\n",
    "\n",
    "\n",
    "class Trainer:\n",
    "\n",
    "    def __init__(self, check_intervals=None):\n",
    "        self._testcases = []\n",
    "        self._envs = [Env.CARTPOLE, Env.LUNARLANDER]\n",
    "        self._algos = [Reinforce, ActorCritic, DQN, DDQN]\n",
    "        self._runners = {Reinforce: ReinforceRunner, ActorCritic: ActorCriticRunner, \n",
    "                        DQN: DQNRunner, DDQN: DDQNRunner}\n",
    "        self._params = {Reinforce: ReinforceParams, ActorCritic: ActorCriticParams, \n",
    "                        DQN: DQNParams, DDQN: DDQNParams}\n",
    "        self._check_intervals = check_intervals\n",
    "        self.allcases = [*itertools.product(self._envs, self._algos)]\n",
    "    \n",
    "    def default_hyperparam(self, env, algo):\n",
    "        algo_param = None\n",
    "\n",
    "        if env == Env.CARTPOLE:\n",
    "            if algo == Reinforce:\n",
    "                algo_param = self._params[algo](\n",
    "                        n_node=128, learning_rate=0.0005, gamma=0.98)\n",
    "            elif algo == ActorCritic:\n",
    "                algo_param = self._params[algo](\n",
    "                        n_node=256, learning_rate=0.0002, gamma=0.98, n_rollout=10)\n",
    "            elif algo == DQN:\n",
    "                algo_param = self._params[algo](\n",
    "                        n_node=128, learning_rate=0.0005, gamma=0.98, buffer_limit=50000, \n",
    "                        batch_size=32, n_train_start=2000, start_epsilon=0.1, update_interval=40)\n",
    "            elif algo == DDQN:\n",
    "                algo_param = self._params[algo](\n",
    "                        n_node=128, learning_rate=0.0005, gamma=0.98, buffer_limit=50000, \n",
    "                        batch_size=32, n_train_start=2000, start_epsilon=0.1, update_interval=40)\n",
    "            else:\n",
    "                raise Exception(f'algorithm does not exist: {algo}')\n",
    "        elif env == Env.LUNARLANDER:\n",
    "            if algo == Reinforce:\n",
    "                algo_param = self._params[algo](\n",
    "                        n_node=128, learning_rate=0.002, gamma=0.98)\n",
    "            elif algo == ActorCritic:\n",
    "                algo_param = self._params[algo](\n",
    "                        n_node=256, learning_rate=0.002, gamma=0.98, n_rollout=20)\n",
    "            elif algo == DQN:\n",
    "                algo_param = self._params[algo](\n",
    "                        n_node=512, learning_rate=0.0005, gamma=0.98, buffer_limit=100000, \n",
    "                        batch_size=64, n_train_start=10000, start_epsilon=0.2, update_interval=20)\n",
    "            elif algo == DDQN:\n",
    "                algo_param = self._params[algo](\n",
    "                        n_node=512, learning_rate=0.0005, gamma=0.98, buffer_limit=100000, \n",
    "                        batch_size=64, n_train_start=10000, start_epsilon=0.2, update_interval=20)\n",
    "            else:\n",
    "                raise Exception(f'algorithm does not exist: {algo}')\n",
    "        else:\n",
    "            raise Exception(f'env does not exist: {env}')\n",
    "\n",
    "        return algo_param\n",
    "\n",
    "    def add_case(self, env, algo, algo_param=None):\n",
    "        algo_param = algo_param if algo_param else self.default_hyperparam(env, algo)\n",
    "        algo_runner = self._runners[algo]\n",
    "        self._testcases += [(env, algo_runner, algo_param)]\n",
    "\n",
    "    def run(self, runner_params=dict()):\n",
    "        runner_params = {**runner_params, \n",
    "                        'save_net':True, 'video_record_interval':0, 'print_interval':0}\n",
    "        runner_param = RunnerParams(**runner_params)\n",
    "\n",
    "        for check_interval in self._check_intervals:\n",
    "            runner_param.check_interval = check_interval\n",
    "\n",
    "            for i, (env, runner, algo_param) in enumerate(self._testcases):\n",
    "                runner_param.name_postfix=str(algo_param)\n",
    "\n",
    "                if env == Env.CARTPOLE:\n",
    "                    runner_param.target_score = 500.0\n",
    "                    runner_param.reward_scale = 100.0\n",
    "                elif env == Env.LUNARLANDER:\n",
    "                    runner_param.target_score = 200.0\n",
    "                    runner_param.reward_scale = 30.0\n",
    "\n",
    "                runner(env.value, algo_param, runner_param).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kuro1\\Source\\Repos\\Remote\\Univ\\graduation-project\\src\\weights 처리중 에러 발생\n",
      "<class 'FileNotFoundError'>\n",
      "(2, '지정된 경로를 찾을 수 없습니다')\n",
      "초기 설정\n",
      "algorithm: Reinforce\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n"
     ]
    }
   ],
   "source": [
    "Remover().remove_dirs(['runs', 'weights', 'videos'])\n",
    "\n",
    "\n",
    "all_cases = Trainer().allcases\n",
    "cartpole_case = filter(lambda x:x[0] == Env.CARTPOLE, all_cases)\n",
    "lunar_case = filter(lambda x:x[0] == Env.LUNARLANDER, all_cases)\n",
    "\n",
    "tr = Trainer([1])\n",
    "\n",
    "for env, algo in [(Env.LUNARLANDER, Reinforce)]:\n",
    "    tr.add_case(env, algo)\n",
    "\n",
    "tr.run()\n",
    "print('전체 테스트 종료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Remover' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24776/1277060193.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'전체 테스트 종료'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0mtuning_reinforce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24776/1277060193.py\u001b[0m in \u001b[0;36mtuning_reinforce\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mtuning_reinforce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mRemover\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_dirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'runs'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weights'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'videos'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLUNARLANDER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mReinforce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0005\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Remover' is not defined"
     ]
    }
   ],
   "source": [
    "def tuning_reinforce():\n",
    "    Remover().remove_dirs(['runs', 'weights', 'videos'])\n",
    "    tr = Trainer([1])\n",
    "    for env, algo in [(Env.LUNARLANDER, Reinforce)]:\n",
    "        start = 0.0005\n",
    "        k = 0.001\n",
    "        for i in range(21):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.learning_rate = start + k*i\n",
    "            tr.add_case(env, algo, hparam)\n",
    "\n",
    "    runner_params = {'max_episode':1000}\n",
    "    tr.run(runner_params)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "tuning_reinforce()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92bb61e8f2b0dcdaa21cd71aad1d97e3da046ad8a677ac321cbd25d595832889"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('py38-pytorch-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
