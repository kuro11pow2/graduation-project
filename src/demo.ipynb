{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nrun tensorboard server\\n\\nconda activate py38-pytorch-gpu && tensorboard --port=6006 --logdir=runs\\nhttp://localhost:6006/\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "run anaconda prompt \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "home_path = os.path.expanduser('~')\n",
    "cur_path = os.getcwd()\n",
    "conda_path = home_path + \"\\\\anaconda3\"\n",
    "conda_script_path = home_path + \"\\\\anaconda3\\\\Scripts\\\\activate.bat\"\n",
    "exc = ' '.join(['start', '%windir%\\System32\\cmd.exe \"/K\"', conda_script_path, conda_path])\n",
    "!$exc\n",
    "\n",
    "\"\"\"\n",
    "run tensorboard server\n",
    "\n",
    "conda activate py38-pytorch-gpu && tensorboard --port=6006 --logdir=runs\n",
    "http://localhost:6006/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manifest import Manifest\n",
    "from logger import Logger\n",
    "from remover import Remover\n",
    "\n",
    "# 자동완성용 import\n",
    "from env import Env\n",
    "from runner import RunnerParams\n",
    "from trainer import Trainer\n",
    "from player import Player\n",
    "\n",
    "from algorithms.dqn import DQN, DQNParams\n",
    "from algorithms.dqn_runner import DQNRunner\n",
    "from algorithms.ddqn import DDQN, DDQNParams\n",
    "from algorithms.ddqn_runner import DDQNRunner\n",
    "from algorithms.reinforce import Reinforce, ReinforceParams\n",
    "from algorithms.reinforce_runner import ReinforceRunner\n",
    "from algorithms.actorcritic import ActorCritic, ActorCriticParams\n",
    "from algorithms.actorcritic_runner import ActorCriticRunner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ActorCritic', 18)\n",
      "('CartPole-v1', 38)\n",
      "('LunarLander-v2', 40)\n",
      "('DDQN', 20)\n",
      "('DQN', 20)\n",
      "('Reinforce', 20)\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "def train():\n",
    "    \n",
    "    all_cases = Trainer().allcases\n",
    "    cartpole_cases = filter(lambda x:x[0] == Env.CARTPOLE, all_cases)\n",
    "    lunar_cases = filter(lambda x:x[0] == Env.LUNARLANDER, all_cases)\n",
    "\n",
    "    check_interval_arr = [5]\n",
    "    tr = Trainer(check_interval_arr)\n",
    "    for env, algo in lunar_cases:\n",
    "        tr.add_case(env, algo)\n",
    "    tr.run()\n",
    "    \n",
    "    check_interval_arr = [10]\n",
    "    tr = Trainer(check_interval_arr)\n",
    "    for env, algo in cartpole_cases:\n",
    "        tr.add_case(env, algo)\n",
    "    tr.run()\n",
    "    \n",
    "\n",
    "def replay():\n",
    "    import os\n",
    "    from collections import defaultdict\n",
    "\n",
    "    PATH = os.path.join(os.getcwd(), 'weights')\n",
    "    filenames = ['.'.join(tokens[:-1]) \n",
    "                        for name in os.listdir(PATH) \n",
    "                        if (tokens := name.split('.')) and len(tokens) > 2]\n",
    "    envs, algos = [], []\n",
    "    for name in filenames:\n",
    "        tokens = name.split('_')\n",
    "        envs += [tokens[0]]\n",
    "        algos += [tokens[1]]\n",
    "    \n",
    "    count = collections.defaultdict(int)\n",
    "\n",
    "    for env, algo in zip(envs, algos):\n",
    "        count[env] += 1\n",
    "        count[algo] += 1\n",
    "        \n",
    "\n",
    "    print(*count.items(), sep='\\n')\n",
    "\n",
    "    Player('weights', filenames).run(debug=True)\n",
    "\n",
    "replay()\n",
    "\n",
    "# Remover().remove_dirs(['runs', 'weights', 'videos'])\n",
    "# Remover().remove_dirs(['logs'])\n",
    "\n",
    "# for i in range(10):\n",
    "#     train()\n",
    "\n",
    "# print_interval=10, max_epi=100 > 4분 35초\n",
    "# print_interval=0, max_epi=100 > 4분 25초\n",
    "# save_check_log=True, print_interval=0, max_epi=100 > 4분 37초\n",
    "\n",
    "# for _ in range(10):\n",
    "#     replay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_reinforce():\n",
    "    tr = Trainer([10])\n",
    "    for env, algo in [(Env.LUNARLANDER, Reinforce)]:\n",
    "        start = 5\n",
    "        k = 5\n",
    "        for i in range(21):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.learning_rate = (start + k*i)/10000\n",
    "            tr.add_case(env, algo, hparam)\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "def tuning_actorcritic():\n",
    "    tr = Trainer([10])\n",
    "    for env, algo in [(Env.LUNARLANDER, ActorCritic)]:\n",
    "        start = 1\n",
    "        k = 5\n",
    "        for i in range(21):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.learning_rate = (start + k*i)/10000\n",
    "            tr.add_case(env, algo, hparam)\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "def tuning_dqn_node_cartpole():\n",
    "    \"\"\"\n",
    "    8\n",
    "    \"\"\"\n",
    "    tr = Trainer([20])\n",
    "    for env, algo in [(Env.CARTPOLE, DQN)]:\n",
    "        n_node = 2\n",
    "        for i in range(8):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.n_node = n_node\n",
    "            tr.add_case(env, algo, hparam)\n",
    "            n_node *= 2\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "def tuning_dqn_node_lunarlander():\n",
    "    \"\"\"\n",
    "    64~256\n",
    "    \"\"\"\n",
    "    tr = Trainer([10])\n",
    "    for env, algo in [(Env.LUNARLANDER, DQN)]:\n",
    "        n_node = 2\n",
    "        for i in range(8):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.n_node = n_node\n",
    "            tr.add_case(env, algo, hparam)\n",
    "            n_node *= 2\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "def tuning_ddqn_node_cartpole():\n",
    "    \"\"\"\n",
    "    8~16\n",
    "    \"\"\"\n",
    "    tr = Trainer([20])\n",
    "    for env, algo in [(Env.CARTPOLE, DDQN)]:\n",
    "        n_node = 64\n",
    "        for i in range(2):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.n_node = n_node\n",
    "            tr.add_case(env, algo, hparam)\n",
    "            n_node *= 2\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "def tuning_ddqn_node_lunarlander():\n",
    "    \"\"\"\n",
    "    32, 128, 256\n",
    "    \"\"\"\n",
    "    tr = Trainer([10])\n",
    "    for env, algo in [(Env.LUNARLANDER, DDQN)]:\n",
    "        n_node = 32\n",
    "        for i in range(4):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.n_node = n_node\n",
    "            tr.add_case(env, algo, hparam)\n",
    "            n_node *= 2\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "# Remover().remove_dirs(['runs', 'weights', 'videos'])\n",
    "# tuning_dqn_node_cartpole()\n",
    "# tuning_dqn_node_lunarlander()\n",
    "tuning_ddqn_node_lunarlander()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92bb61e8f2b0dcdaa21cd71aad1d97e3da046ad8a677ac321cbd25d595832889"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('py38-pytorch-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
