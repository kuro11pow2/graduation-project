{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "run anaconda prompt \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "home_path = os.path.expanduser('~')\n",
    "cur_path = os.getcwd()\n",
    "conda_path = home_path + \"\\\\anaconda3\"\n",
    "conda_script_path = home_path + \"\\\\anaconda3\\\\Scripts\\\\activate.bat\"\n",
    "exc = ' '.join(['start', '%windir%\\System32\\cmd.exe \"/K\"', conda_script_path, conda_path])\n",
    "!$exc\n",
    "\n",
    "\"\"\"\n",
    "run tensorboard server\n",
    "\n",
    "conda activate py38-pytorch-gpu && tensorboard --port=6006 --logdir=runs\n",
    "http://localhost:6006/\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 212.38898994006377\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 213.32533953809516\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 205.03419902320607\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 206.2943887187817\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 236.43637720242063\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 210.9443631407214\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 220.54882554736014\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 227.11291192578898\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 239.19147380257155\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 207.90446887281723\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "10000 에피소드 초과하여 종료\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 204.41235356484154\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 230.8654758182838\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 227.36315722966592\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 243.26729446318285\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 208.72974166694888\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 220.15184832430313\n",
      "시뮬레이션 종료, 네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "종료 조건 만족. 최종 5번 평균 점수 221.23851648466234\n",
      "시뮬레이션 종료, 네트워크 저장\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from manifest import Manifest\n",
    "from logger import Logger\n",
    "from remover import Remover\n",
    "\n",
    "# 자동완성용 import\n",
    "from env import Env\n",
    "from runner import RunnerParams\n",
    "from trainer import Trainer\n",
    "from player import Player\n",
    "\n",
    "from algorithms.dqn import DQN, DQNParams\n",
    "from algorithms.dqn_runner import DQNRunner\n",
    "from algorithms.ddqn import DDQN, DDQNParams\n",
    "from algorithms.ddqn_runner import DDQNRunner\n",
    "from algorithms.reinforce import Reinforce, ReinforceParams\n",
    "from algorithms.reinforce_runner import ReinforceRunner\n",
    "from algorithms.actorcritic import ActorCritic, ActorCriticParams\n",
    "from algorithms.actorcritic_runner import ActorCriticRunner\n",
    "\n",
    "\n",
    "import collections\n",
    "\n",
    "def train():\n",
    "    cases = Trainer().allcases\n",
    "    cartpole_cases = filter(lambda x:x[0] == Env.CARTPOLE, cases)\n",
    "    lunar_cases = filter(lambda x:x[0] == Env.LUNARLANDER, cases)\n",
    "\n",
    "    check_interval_arr = [5]\n",
    "    tr = Trainer(check_interval_arr)\n",
    "    for env, algo in lunar_cases:\n",
    "        tr.add_case(env, algo)\n",
    "    tr.run()\n",
    "    \n",
    "    check_interval_arr = [10]\n",
    "    tr = Trainer(check_interval_arr)\n",
    "    for env, algo in cartpole_cases:\n",
    "        tr.add_case(env, algo)\n",
    "    tr.run()\n",
    "    \n",
    "\n",
    "def play():\n",
    "    PATH = os.path.join(os.getcwd(), 'weights')\n",
    "    filenames = ['.'.join(tokens[:-1]) \n",
    "                        for name in os.listdir(PATH) \n",
    "                        if (tokens := name.split('.')) and len(tokens) > 2]\n",
    "\n",
    "    Player('weights', filenames).run(runner_param_dic={'max_episode': 125})\n",
    "\n",
    "\n",
    "def train_dqn_ddqn():\n",
    "    cases = Trainer().allcases\n",
    "    target_cases = filter(lambda x:(x[1] == DQN) or (x[1] == DDQN), cases)\n",
    "    cartpole_cases = filter(lambda x:x[0] == Env.CARTPOLE, target_cases)\n",
    "    lunar_cases = filter(lambda x:x[0] == Env.LUNARLANDER, target_cases)\n",
    "\n",
    "    check_interval_arr = [5]\n",
    "    tr = Trainer(check_interval_arr)\n",
    "    for env, algo in lunar_cases:\n",
    "        tr.add_case(env, algo)\n",
    "    tr.run()\n",
    "    \n",
    "    # check_interval_arr = [10]\n",
    "    # tr = Trainer(check_interval_arr)\n",
    "    # for env, algo in cartpole_cases:\n",
    "    #     tr.add_case(env, algo)\n",
    "    # tr.run()\n",
    "\n",
    "for i in range(10):\n",
    "    train_dqn_ddqn()\n",
    "\n",
    "# Remover().remove_dirs(['runs', 'weights', 'videos'])\n",
    "# Remover().remove_dirs(['logs'])\n",
    "\n",
    "# for i in range(10):\n",
    "#     train()\n",
    "\n",
    "# print_interval=10, max_epi=100 > 4분 35초\n",
    "# print_interval=0, max_epi=100 > 4분 25초\n",
    "# save_check_log=True, print_interval=0, max_epi=100 > 4분 37초\n",
    "\n",
    "# for _ in range(10):\n",
    "#     replay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_reinforce():\n",
    "    tr = Trainer([10])\n",
    "    for env, algo in [(Env.LUNARLANDER, Reinforce)]:\n",
    "        start = 5\n",
    "        k = 5\n",
    "        for i in range(21):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.learning_rate = (start + k*i)/10000\n",
    "            tr.add_case(env, algo, hparam)\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "def tuning_actorcritic():\n",
    "    tr = Trainer([10])\n",
    "    for env, algo in [(Env.LUNARLANDER, ActorCritic)]:\n",
    "        start = 1\n",
    "        k = 5\n",
    "        for i in range(21):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.learning_rate = (start + k*i)/10000\n",
    "            tr.add_case(env, algo, hparam)\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "def tuning_dqn_node_cartpole():\n",
    "    \"\"\"\n",
    "    8\n",
    "    \"\"\"\n",
    "    tr = Trainer([20])\n",
    "    for env, algo in [(Env.CARTPOLE, DQN)]:\n",
    "        n_node = 2\n",
    "        for i in range(8):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.n_node = n_node\n",
    "            tr.add_case(env, algo, hparam)\n",
    "            n_node *= 2\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "def tuning_dqn_node_lunarlander():\n",
    "    \"\"\"\n",
    "    64~256\n",
    "    \"\"\"\n",
    "    tr = Trainer([10])\n",
    "    for env, algo in [(Env.LUNARLANDER, DQN)]:\n",
    "        n_node = 2\n",
    "        for i in range(8):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.n_node = n_node\n",
    "            tr.add_case(env, algo, hparam)\n",
    "            n_node *= 2\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "def tuning_ddqn_node_cartpole():\n",
    "    \"\"\"\n",
    "    8~16\n",
    "    \"\"\"\n",
    "    tr = Trainer([20])\n",
    "    for env, algo in [(Env.CARTPOLE, DDQN)]:\n",
    "        n_node = 64\n",
    "        for i in range(2):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.n_node = n_node\n",
    "            tr.add_case(env, algo, hparam)\n",
    "            n_node *= 2\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "def tuning_ddqn_node_lunarlander():\n",
    "    \"\"\"\n",
    "    32, 128, 256\n",
    "    \"\"\"\n",
    "    tr = Trainer([10])\n",
    "    for env, algo in [(Env.LUNARLANDER, DDQN)]:\n",
    "        n_node = 32\n",
    "        for i in range(4):\n",
    "            hparam = tr.default_hyperparam(env, algo)\n",
    "            hparam.n_node = n_node\n",
    "            tr.add_case(env, algo, hparam)\n",
    "            n_node *= 2\n",
    "\n",
    "    runner_param_dic = {'save_net':True, 'max_episode':10000, 'print_interval':0, 'video_record_interval':0}\n",
    "    tr.run(runner_param_dic)\n",
    "    print('전체 테스트 종료')\n",
    "\n",
    "# Remover().remove_dirs(['runs', 'weights', 'videos'])\n",
    "# tuning_dqn_node_cartpole()\n",
    "# tuning_dqn_node_lunarlander()\n",
    "tuning_ddqn_node_lunarlander()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92bb61e8f2b0dcdaa21cd71aad1d97e3da046ad8a677ac321cbd25d595832889"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('py38-pytorch-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
