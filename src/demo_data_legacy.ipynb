{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_log():\n",
    "    \"\"\"\n",
    "    ./logs의 모든 로그를 (알고리즘, 환경) 별로 모아서 저장\n",
    "    \"\"\"\n",
    "\n",
    "    import os, time\n",
    "    import pandas as pd\n",
    "    from collections import defaultdict\n",
    "\n",
    "    PATH = os.path.join(os.getcwd(), 'logs')\n",
    "    filename_list = ['.'.join(tokens[:-1]) \n",
    "                        for name in os.listdir(PATH) \n",
    "                        if (tokens := name.split('.')) and len(tokens) > 2]\n",
    "    fileinfo_list = [name.split('_')[:2] for name in filename_list]\n",
    "    list(map(lambda x:x.split('_')[:2], filename_list))\n",
    "\n",
    "    cases = defaultdict(list)\n",
    "\n",
    "    for (algo, env), filename in zip(fileinfo_list, filename_list):\n",
    "        load_path = os.path.join(PATH, filename) + '.csv'\n",
    "        save_path = os.path.join(PATH, f'{algo}_{env}_{int(time.time())}') + '.csv'\n",
    "        cases[save_path].append(load_path)\n",
    "\n",
    "    count = defaultdict(int)\n",
    "\n",
    "    for save_path in cases:\n",
    "        outp = pd.DataFrame()\n",
    "        \n",
    "        for load_path in cases[save_path]:\n",
    "            print(save_path)\n",
    "            print(f'로드: {load_path}')\n",
    "            inp = pd.read_csv(load_path)\n",
    "            last_epi = inp['episode'].max()\n",
    "            inp['episode'] += count[save_path]\n",
    "            print(count[save_path])\n",
    "            count[save_path] += last_epi + 1\n",
    "            \n",
    "            outp = pd.concat([outp, inp])\n",
    "\n",
    "        outp.to_csv(save_path, index=False, encoding='utf-8')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def draw_corr_mat_heatmap(dataframe, *, figsize=(10, 10), drop_columns=[]):\n",
    "    \n",
    "    dataframe.drop(columns=drop_columns, inplace=True) # 지정된 열을 삭제\n",
    "    corr_df = dataframe.corr() # 쌍별 상관관계 행렬\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # 원소가 1인 상부삼각행렬\n",
    "    masked = np.zeros_like(corr_df, dtype=np.bool)\n",
    "    masked[np.triu_indices_from(masked)] = True\n",
    "\n",
    "    sns.heatmap(\n",
    "        corr_df,\n",
    "        cmap=sns.color_palette(\"RdBu\", 10),\n",
    "        annot=True,  # 실제 값을 표시한다\n",
    "        mask=masked,  # 숨길 위치 = True\n",
    "        linewidths=.5,  # 셀의 경계선 너비\n",
    "        cbar_kws={\"shrink\": .5},  # 컬러바 크기 설정\n",
    "        vmin=-1, # 컬러바 범위 설정 [-1, 1]\n",
    "        vmax=1  \n",
    "    )\n",
    "\n",
    "    plt.title('Correation Matrix', fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "def visualize(df, *, figsize=(5, 5), graph_drop_cols=['reward', 'done', 'step'], corr_drop_cols=['reward', 'done', 'action', 'episode', 'step']):\n",
    "    sns.set_palette(\"pastel\")\n",
    "    plt.figure(figsize=figsize) # 피규어 생성\n",
    "    df_group_by = df.groupby(by='episode') # 'episode' 레이블로 그룹화\n",
    "    max_steps = df_group_by[\"step\"].max() # 각 그룹에서 'step' 레이블의 max를 구함\n",
    "    max_step_df = pd.DataFrame(max_steps) # step의 max값으로 df를 만든다.\n",
    "    max_step_df.reset_index(inplace=True)\n",
    "\n",
    "    plt.title(\"max step histogram\")\n",
    "    sns.histplot(data=max_step_df, x=max_step_df.step) # 히스토그램 출력\n",
    "    plt.show()\n",
    "\n",
    "    draw_corr_mat_heatmap(df, drop_columns=corr_drop_cols) # 상관관계행렬 heatmap 출력\n",
    "\n",
    "    # 그래프\n",
    "    col_names = [col for col in df.columns.to_list() if col not in set(graph_drop_cols)]\n",
    "\n",
    "    for col in col_names:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "        sns.histplot(x=df[col])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def load_log(filename):\n",
    "    df = pd.read_csv(f\"./logs/{filename}.csv\")\n",
    "    env_name = filename.split('_')[1].split('-')[0]\n",
    "    if env_name == 'CartPole':\n",
    "        df.rename(columns = {\n",
    "            'state0' : 'Cart Position',\n",
    "            'state1' : 'Cart Velocity',\n",
    "            'state2' : 'Pole Angle',\n",
    "            'state3' : 'Pole Angular Velocity'\n",
    "            }, inplace = True)\n",
    "    elif env_name == 'LunarLander':\n",
    "        df.rename(columns = {\n",
    "            'state0' : 'Horizontal Coord',\n",
    "            'state1' : 'Vertical Coord',\n",
    "            'state2' : 'Horizontal Speed',\n",
    "            'state3' : 'Vertical Speed',\n",
    "            'state4' : 'Angle',\n",
    "            'state5' : 'Angular Speed',\n",
    "            'state6' : 'First Leg',\n",
    "            'state7' : 'Second Leg'\n",
    "            }, inplace = True)\n",
    "    return df\n",
    "\n",
    "# df = load_log('ActorCritic_LunarLander-v2_1635373522')\n",
    "# sns.set_style('whitegrid')\n",
    "\n",
    "# fig = plt.figure(figsize=(10, 5))\n",
    "# area1 = fig.add_subplot(1, 3, 1)\n",
    "# area2 = fig.add_subplot(1, 3, 2)\n",
    "# fig.show()\n",
    "\n",
    "def demo():\n",
    "    df = load_log('ActorCritic_LunarLander-v2_1635373522')\n",
    "    df = df.drop(['reward', 'episode', 'done'], axis=1)\n",
    "    print(f'데이터 개수: {len(df)}')\n",
    "\n",
    "\n",
    "    def dim1():\n",
    "        \"\"\"\n",
    "        실수 분포 플롯은 자료의 분포를 묘사하기 위한 것으로 Matplotlib의 단순한 히스토그램과 달리 \n",
    "        커널 밀도(kernel density) 및 러그(rug) 표시 기능 및 다차원 복합 분포 기능 등을 제공한다. \n",
    "        1차원 실수 분포 플롯 명령에는 rugplot, kdeplot, distplot이 있다.\n",
    "\n",
    "        러그(rug) 플롯은 데이터 위치를 x축 위에 작은 선분(rug)으로 나타내어 실제 데이터들의 위치를 보여준다.\n",
    "        \"\"\"\n",
    "        data = df['Angular Speed']\n",
    "        sns.rugplot(data) # 데이터 위치 표시\n",
    "        plt.title(\"Angular Speed\")\n",
    "        plt.show()\n",
    "\n",
    "        sns.kdeplot(data) # 커널 밀도 표시 (히스토그램보다 부드러운 형태의 분포 곡선)\n",
    "        plt.title(\"Angular Speed\")\n",
    "        plt.show()\n",
    "\n",
    "        sns.distplot(data, kde=True, rug=True)\n",
    "        plt.title(\"Angular Speed\")\n",
    "        plt.show()\n",
    "\n",
    "        \"\"\"\n",
    "        countplot 명령을 사용하면 각 카테고리 값별로 데이터가 얼마나 있는지 표시할 수 있다.\n",
    "        countplot 명령은 데이터프레임에만 사용할 수 있다. 사용 방법은 다음과 같다.\n",
    "        data 인수에는 대상이 되는 데이터프레임을, x 인수에는 데이터프레임의 열 이름 문자열을 넣는다.\n",
    "        \"\"\"\n",
    "        sns.countplot(x=\"action\", data=df)\n",
    "        plt.title(\"action\")\n",
    "        plt.show()\n",
    "    \n",
    "    def dim2():\n",
    "        \"\"\"\n",
    "        분석하고자 하는 데이터가 2차원이고 실수 값인 경우\n",
    "        \"\"\"\n",
    "        df2 = df\n",
    "        x_feat, y_feat = \"step\", \"Angle\"\n",
    "        sns.jointplot(x=x_feat, y=y_feat, data=df2, kind=\"scatter\")\n",
    "        plt.suptitle(\"2d jointplot\", y=1.02)\n",
    "        plt.show()\n",
    "\n",
    "        # kernel density의 경우 시간초과\n",
    "        # sns.jointplot(x=x_feat, y=y_feat, data=df[:10000], kind=\"kde\")\n",
    "        # plt.suptitle(\"2d jointplot kernel density\", y=1.02)\n",
    "        # plt.show()\n",
    "\n",
    "        sns.barplot(x='action', y=y_feat, data=df2)\n",
    "        plt.title(\"2d barplot\")\n",
    "        plt.show()\n",
    "\n",
    "    def dimn():\n",
    "        \"\"\"\n",
    "        3차원 이상의 실수 데이터\n",
    "        \"\"\"\n",
    "        # sns.pairplot(df, corner=True)\n",
    "        # plt.title(\"pairplot\")\n",
    "        # plt.show()\n",
    "        # \"\"\"\n",
    "        # 3차원 이상의 실수 데이터\n",
    "        # \"\"\"\n",
    "        # g = sns.pairplot(df, diag_kind=\"kde\", corner=True)\n",
    "        # g.map_lower(sns.kdeplot, levels=4, color=\".2\")\n",
    "        # \"\"\"\n",
    "        # 3차원 이상의 실수-카테고리 데이터\n",
    "        # \"\"\"\n",
    "        # sns.pairplot(df, hue=\"action\", corner=True)\n",
    "        # plt.title(\"pairplot\")\n",
    "        # plt.show()\n",
    "\n",
    "        sns.pairplot(df, kind=\"hist\", corner=True)\n",
    "        \n",
    "    def demo_pandas():\n",
    "        df.drop(['step'], axis=1).plot.box()\n",
    "        plt.title(\"hist Box Plot\")\n",
    "        plt.xlabel(\"Feature\")\n",
    "        plt.ylabel(\"value\")\n",
    "        plt.show()\n",
    "\n",
    "    dim2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CartPole-v1, step\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  483170.000000  624083.000000  614297.000000  550799.000000\n",
      "mean      244.165944     249.361180     246.526459     232.396713\n",
      "std       143.056359     144.353896     143.598156     141.732825\n",
      "min         0.000000       0.000000       0.000000       0.000000\n",
      "25%       120.000000     124.000000     122.000000     110.000000\n",
      "50%       242.000000     249.000000     245.000000     224.000000\n",
      "75%       366.000000     374.000000     370.000000     351.000000\n",
      "max       499.000000     499.000000     499.000000     499.000000\n",
      "\n",
      "CartPole-v1, episode\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  483170.000000  624083.000000  614297.000000  550799.000000\n",
      "mean      496.695778     624.321451     622.189075     624.967642\n",
      "std       288.650826     360.976655     362.721019     360.697194\n",
      "min         0.000000       0.000000       0.000000       0.000000\n",
      "25%       248.000000     312.000000     308.000000     316.000000\n",
      "50%       494.000000     625.000000     615.000000     624.000000\n",
      "75%       745.000000     937.000000     942.000000     939.000000\n",
      "max       999.000000    1249.000000    1249.000000    1249.000000\n",
      "\n",
      "CartPole-v1, reward\n",
      "       ActorCritic      DDQN       DQN  Reinforce\n",
      "count     483170.0  624083.0  614297.0   550799.0\n",
      "mean           1.0       1.0       1.0        1.0\n",
      "std            0.0       0.0       0.0        0.0\n",
      "min            1.0       1.0       1.0        1.0\n",
      "25%            1.0       1.0       1.0        1.0\n",
      "50%            1.0       1.0       1.0        1.0\n",
      "75%            1.0       1.0       1.0        1.0\n",
      "max            1.0       1.0       1.0        1.0\n",
      "\n",
      "CartPole-v1, action\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  483170.000000  624083.000000  614297.000000  550799.000000\n",
      "mean        0.499979       0.499792       0.499231       0.500081\n",
      "std         0.500001       0.500000       0.500000       0.500000\n",
      "min         0.000000       0.000000       0.000000       0.000000\n",
      "25%         0.000000       0.000000       0.000000       0.000000\n",
      "50%         0.000000       0.000000       0.000000       1.000000\n",
      "75%         1.000000       1.000000       1.000000       1.000000\n",
      "max         1.000000       1.000000       1.000000       1.000000\n",
      "\n",
      "CartPole-v1, Cart Position\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  483170.000000  624083.000000  614297.000000  550799.000000\n",
      "mean        0.049860       0.542301       0.159241      -0.060633\n",
      "std         0.674194       1.097510       1.022237       0.794482\n",
      "min        -2.399734      -2.224933      -2.399738      -2.399841\n",
      "25%        -0.245445      -0.179896      -0.196937      -0.506565\n",
      "50%         0.023240       0.436885       0.098960      -0.024114\n",
      "75%         0.353442       1.580797       0.905194       0.369339\n",
      "max         2.399555       2.399577       2.069513       2.399977\n",
      "\n",
      "CartPole-v1, Cart Velocity\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  483170.000000  624083.000000  614297.000000  550799.000000\n",
      "mean        0.008579       0.054886       0.007115      -0.008097\n",
      "std         0.378207       0.341370       0.316089       0.554076\n",
      "min        -1.933780      -1.332828      -1.861000      -3.299146\n",
      "25%        -0.213881      -0.173124      -0.169102      -0.363797\n",
      "50%         0.005104       0.006802       0.010359      -0.002872\n",
      "75%         0.222534       0.201871       0.186268       0.354324\n",
      "max         1.951312       1.883745       1.717702       2.810836\n",
      "\n",
      "CartPole-v1, Pole Angle\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  483170.000000  624083.000000  614297.000000  550799.000000\n",
      "mean       -0.000091      -0.000319      -0.001432       0.000038\n",
      "std         0.053512       0.028469       0.032009       0.063333\n",
      "min        -0.209294      -0.206663      -0.183616      -0.209423\n",
      "25%        -0.032957      -0.007732      -0.007859      -0.040910\n",
      "50%         0.000546      -0.000504      -0.000942       0.000635\n",
      "75%         0.033011       0.006081       0.005203       0.041250\n",
      "max         0.209439       0.172528       0.205878       0.209335\n",
      "\n",
      "CartPole-v1, Pole Angular Velocity\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  483170.000000  624083.000000  614297.000000  550799.000000\n",
      "mean       -0.000142       0.000362      -0.000882      -0.000391\n",
      "std         0.331814       0.249061       0.209188       0.315093\n",
      "min        -1.902341      -1.190817      -1.451019      -1.715220\n",
      "25%        -0.219018      -0.160982      -0.146990      -0.213865\n",
      "50%         0.001077      -0.002882      -0.002272       0.000801\n",
      "75%         0.220647       0.171080       0.162224       0.215294\n",
      "max         1.987328       1.513161       0.885922       1.467466\n",
      "\n",
      "\n",
      "LunarLander-v2, step\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  760799.000000  845375.000000  770632.000000  738722.000000\n",
      "mean      373.946868     398.824577     375.312711     375.315353\n",
      "std       269.169441     272.373631     258.963124     272.700361\n",
      "min         0.000000       0.000000       0.000000       0.000000\n",
      "25%       152.000000     169.000000     156.000000     148.000000\n",
      "50%       316.000000     352.000000     333.000000     314.000000\n",
      "75%       556.000000     601.000000     564.000000     569.000000\n",
      "max       999.000000     999.000000     999.000000     999.000000\n",
      "\n",
      "LunarLander-v2, episode\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  760799.000000  845375.000000  770632.000000  738722.000000\n",
      "mean      639.386529     623.776975     579.556808     576.521881\n",
      "std       346.033198     376.001337     358.631866     348.802692\n",
      "min         0.000000       0.000000       0.000000       0.000000\n",
      "25%       347.000000     310.000000     251.000000     272.000000\n",
      "50%       658.000000     587.000000     560.000000     562.000000\n",
      "75%       932.000000     981.000000     915.000000     854.000000\n",
      "max      1249.000000    1249.000000    1249.000000    1249.000000\n",
      "\n",
      "LunarLander-v2, reward\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  760799.000000  845375.000000  770632.000000  738722.000000\n",
      "mean        0.242153       0.091823       0.152733       0.212969\n",
      "std         3.936057       3.683250       4.202291       4.123886\n",
      "min      -100.000000    -100.000000    -100.000000    -100.000000\n",
      "25%        -0.648259      -1.075302      -1.201659      -0.635165\n",
      "50%        -0.001513      -0.044024      -0.015509      -0.047532\n",
      "75%         1.072257       1.039262       1.158021       0.952733\n",
      "max       100.000000     100.000000     119.128913     100.000000\n",
      "\n",
      "LunarLander-v2, action\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  760799.000000  845375.000000  770632.000000  738722.000000\n",
      "mean        1.720139       1.529434       1.514531       1.794389\n",
      "std         0.986182       0.985533       0.997784       0.943527\n",
      "min         0.000000       0.000000       0.000000       0.000000\n",
      "25%         1.000000       1.000000       1.000000       1.000000\n",
      "50%         2.000000       2.000000       2.000000       2.000000\n",
      "75%         3.000000       2.000000       2.000000       3.000000\n",
      "max         3.000000       3.000000       3.000000       3.000000\n",
      "\n",
      "LunarLander-v2, Horizontal Coord\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  760799.000000  845375.000000  770632.000000  738722.000000\n",
      "mean        0.077329      -0.153966      -0.112330      -0.074057\n",
      "std         0.170147       0.399487       0.361385       0.228490\n",
      "min        -0.427980      -0.999999      -0.999998      -0.998969\n",
      "25%        -0.053954      -0.452325      -0.305540      -0.217483\n",
      "50%         0.081866      -0.149545      -0.065521      -0.091816\n",
      "75%         0.187036       0.139305       0.116009       0.082934\n",
      "max         0.630212       0.999877       0.999969       0.999531\n",
      "\n",
      "LunarLander-v2, Vertical Coord\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  760799.000000  845375.000000  770632.000000  738722.000000\n",
      "mean        0.309712       0.438830       0.365150       0.263271\n",
      "std         0.421822       0.451117       0.404015       0.427660\n",
      "min        -0.224234      -0.338325      -0.359723      -0.347790\n",
      "25%        -0.000917       0.062400       0.058936      -0.001909\n",
      "50%         0.081276       0.300511       0.217134       0.008980\n",
      "75%         0.530649       0.699385       0.565342       0.429565\n",
      "max         1.530524       2.483769       2.341424       1.604126\n",
      "\n",
      "LunarLander-v2, Horizontal Speed\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  760799.000000  845375.000000  770632.000000  738722.000000\n",
      "mean        0.018600      -0.023931      -0.009951      -0.020278\n",
      "std         0.124866       0.170510       0.167576       0.164230\n",
      "min        -0.808086      -0.966156      -0.888238      -1.133655\n",
      "25%        -0.009301      -0.083785      -0.056830      -0.062237\n",
      "50%         0.001944      -0.010685      -0.003237      -0.002952\n",
      "75%         0.044506       0.037171       0.037872       0.011611\n",
      "max         0.808280       1.668275       1.491942       0.931897\n",
      "\n",
      "LunarLander-v2, Vertical Speed\n",
      "        ActorCritic          DDQN            DQN      Reinforce\n",
      "count  7.607990e+05  8.453750e+05  770632.000000  738722.000000\n",
      "mean  -1.035793e-01 -8.412179e-02      -0.099722      -0.107699\n",
      "std    1.393395e-01  1.466489e-01       0.167612       0.156833\n",
      "min   -1.210846e+00 -1.076861e+00      -1.823929      -1.006733\n",
      "25%   -1.663532e-01 -1.160655e-01      -0.108392      -0.199762\n",
      "50%   -5.962604e-02 -2.562845e-02      -0.034999      -0.002580\n",
      "75%    2.076753e-08  6.361844e-08      -0.004032       0.000005\n",
      "max    5.108696e-01  7.933827e-01       0.511014       0.548155\n",
      "\n",
      "LunarLander-v2, Angle\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  760799.000000  845375.000000  770632.000000  738722.000000\n",
      "mean       -0.009824      -0.001254      -0.003636       0.014068\n",
      "std         0.120260       0.106882       0.126108       0.140172\n",
      "min        -0.963771      -2.000932      -3.593524      -2.053104\n",
      "25%        -0.043287      -0.037149      -0.039372      -0.045575\n",
      "50%        -0.001119      -0.003130      -0.002183       0.001284\n",
      "75%         0.027575       0.032878       0.033120       0.071159\n",
      "max         0.840899       1.605892       2.292164       1.426020\n",
      "\n",
      "LunarLander-v2, Angular Speed\n",
      "        ActorCritic          DDQN           DQN     Reinforce\n",
      "count  7.607990e+05  8.453750e+05  7.706320e+05  7.387220e+05\n",
      "mean  -2.484728e-04 -2.280162e-04 -1.200970e-03  2.452321e-05\n",
      "std    1.041043e-01  9.000571e-02  1.007431e-01  1.225500e-01\n",
      "min   -1.884762e+00 -1.880638e+00 -4.799238e+00 -1.729544e+00\n",
      "25%   -1.657870e-02 -2.899908e-02 -3.571407e-02 -1.478984e-02\n",
      "50%    7.945043e-07 -2.450563e-07 -8.376758e-08  1.163780e-07\n",
      "75%    1.809865e-02  2.875770e-02  3.387614e-02  1.595418e-02\n",
      "max    1.858125e+00  1.766719e+00  2.320911e+00  1.751960e+00\n",
      "\n",
      "LunarLander-v2, First Leg\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  760799.000000  845375.000000  770632.000000  738722.000000\n",
      "mean        0.392257       0.116586       0.114841       0.496991\n",
      "std         0.488254       0.320927       0.318830       0.499991\n",
      "min         0.000000       0.000000       0.000000       0.000000\n",
      "25%         0.000000       0.000000       0.000000       0.000000\n",
      "50%         0.000000       0.000000       0.000000       0.000000\n",
      "75%         1.000000       0.000000       0.000000       1.000000\n",
      "max         1.000000       1.000000       1.000000       1.000000\n",
      "\n",
      "LunarLander-v2, Second Leg\n",
      "         ActorCritic           DDQN            DQN      Reinforce\n",
      "count  760799.000000  845375.000000  770632.000000  738722.000000\n",
      "mean        0.382778       0.111366       0.119636       0.502649\n",
      "std         0.486065       0.314585       0.324535       0.499993\n",
      "min         0.000000       0.000000       0.000000       0.000000\n",
      "25%         0.000000       0.000000       0.000000       0.000000\n",
      "50%         0.000000       0.000000       0.000000       1.000000\n",
      "75%         1.000000       0.000000       0.000000       1.000000\n",
      "max         1.000000       1.000000       1.000000       1.000000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def print_statistics():\n",
    "    cases = dict()\n",
    "    cases[\"CartPole-v1\"] = [\n",
    "        \"DQN_CartPole-v1_train=False_intvl=1_rwdscl=1.0_node=128_lRate=0.0005_gma=0.98_nBuf=50000_nBat=32_nStrt=2000_updIntvl=10_1635102083\"]\n",
    "    # cases[\"LunarLander-v2\"] = [\n",
    "    #     \"Reinforce_LunarLander-v2_train=False_intvl=1_rwdscl=1.0_node=256_lRate=0.0025_gma=0.98_1634919662\",\n",
    "    #     \"ActorCritic_LunarLander-v2_train=False_intvl=1_rwdscl=1.0_node=256_lRate=0.0025_gma=0.98_nRoll=20_1634920427\",\n",
    "    #     \"DQN_LunarLander-v2_train=False_intvl=1_rwdscl=1.0_node=256_lRate=0.0005_gma=0.98_nBuf=100000_nBat=64_nStrt=10000_updIntvl=20_1634920703\",\n",
    "    #     \"DDQN_LunarLander-v2_train=False_intvl=1_rwdscl=1.0_node=256_lRate=0.0005_gma=0.98_nBuf=100000_nBat=64_nStrt=10000_updIntvl=20_1634921263\"]\n",
    "\n",
    "    for env in cases:\n",
    "        print(f'\\n\\t<<{env}>>')\n",
    "        feature_data_list = defaultdict(pd.DataFrame)\n",
    "        for filename in cases[env]:\n",
    "            print(filename)\n",
    "            algo = filename.split('_')[0]\n",
    "            df = load_log(filename)\n",
    "            for col in df.columns:\n",
    "                sr = df[[col]].squeeze()\n",
    "                sr.rename(algo, inplace=True)\n",
    "                feature_data_list[col] = pd.concat([feature_data_list[col], sr], axis=1)\n",
    "        for feature in feature_data_list:\n",
    "            print(f'\\n\\t<{feature}>')\n",
    "            df_stats = feature_data_list[feature].describe()\n",
    "            print(df_stats)\n",
    "\n",
    "def get_compare_statics(env_algo_dic):\n",
    "    statics = dict()\n",
    "    for env, algo_dic in env_algo_dic.items():\n",
    "        statics[env] = statics.get(env, defaultdict(pd.DataFrame))\n",
    "        for algo, df in algo_dic.items():\n",
    "            describe = df.describe()\n",
    "            for col in describe.columns:\n",
    "                sr = describe[[col]].squeeze()\n",
    "                sr.rename(algo, inplace=True)\n",
    "                statics[env][col] = pd.concat([statics[env][col], sr], axis=1)\n",
    "    return statics\n",
    "\n",
    "def main():\n",
    "    PATH = os.path.join(os.getcwd(), 'logs')\n",
    "    filenames = []\n",
    "    for name in os.listdir(PATH):\n",
    "        tokens = [*name.split('.')]\n",
    "        filename = None\n",
    "        if len(tokens) > 2:\n",
    "            filename = '.'.join(tokens[:-1])\n",
    "        else:\n",
    "            filename = tokens[0]\n",
    "\n",
    "        filenames.append(filename)\n",
    "    \n",
    "\n",
    "    dfs = list(map(load_log, filenames))\n",
    "\n",
    "    def compare():\n",
    "        env_algo_dic = dict()\n",
    "        \n",
    "        # 에피소드별 최종 스텝 추가 필요\n",
    "        for df, filename in zip(dfs, filenames):\n",
    "            tokens = filename.split('_')\n",
    "            algo, env, *_ = tokens\n",
    "            env_algo_dic[env] = env_algo_dic.get(env, dict())\n",
    "\n",
    "            if algo in env_algo_dic[env]:\n",
    "                env_algo_dic[env][algo] = pd.concat([env_algo_dic[env][algo], df])\n",
    "            else:\n",
    "                env_algo_dic[env][algo] = df\n",
    "\n",
    "        statics = get_compare_statics(env_algo_dic)\n",
    "        for env in statics:\n",
    "            for feature in statics[env]:\n",
    "                print(f'{env}, {feature}')\n",
    "                print(statics[env][feature])\n",
    "                print()\n",
    "            print()\n",
    "\n",
    "    def visual():\n",
    "        for df, filename in zip(dfs, filenames):\n",
    "            print(filename)\n",
    "            visualize(df)\n",
    "\n",
    "    compare()\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by='episode')[\"step\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_value = pd.DataFrame(df.groupby(by='episode')[\"step\"].max())\n",
    "step_value.reset_index(inplace=True)\n",
    "step_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=step_value,x=step_value.step,bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"last step hist\")\n",
    "sns.histplot(x=df[\"step\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92bb61e8f2b0dcdaa21cd71aad1d97e3da046ad8a677ac321cbd25d595832889"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('py38-pytorch-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
