{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "run anaconda prompt \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "home_path = os.path.expanduser('~')\n",
    "cur_path = os.getcwd()\n",
    "conda_path = home_path + \"\\\\anaconda3\"\n",
    "conda_script_path = home_path + \"\\\\anaconda3\\\\Scripts\\\\activate.bat\"\n",
    "exc = ' '.join(['start', '%windir%\\System32\\cmd.exe \"/K\"', conda_script_path, conda_path])\n",
    "!$exc\n",
    "\n",
    "\"\"\"\n",
    "run tensorboard server\n",
    "\n",
    "conda activate py38-pytorch-gpu && tensorboard --port=6006 --logdir=runs\n",
    "http://localhost:6006/\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "print env info\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "run tensorboard server\n",
    "\n",
    "conda activate py38-pytorch-gpu && tensorboard --port=6006 --logdir=runs\n",
    "http://localhost:6006/\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "print env info\n",
    "\"\"\"\n",
    "\n",
    "import gym\n",
    "from env import Env\n",
    "\n",
    "env = gym.make(Env.BIPEDALWALKER.value)\n",
    "\n",
    "print(dir(env))\n",
    "print(f'{env._max_episode_steps=}')\n",
    "print(f'{env.action_space=}')\n",
    "print(f'{env.metadata=}')\n",
    "print(f'{env.observation_space.shape[0]=}')\n",
    "print(f'{env.reward_range=}')\n",
    "print(f'{env.seed=}')\n",
    "print(f'{env.spec=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: CartPole-v1\n",
      "state space: (4,)\n",
      "action space: Discrete(2)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: 8.0\n",
      "n_buffer : 961, eps : 9.5%\n",
      "에피소드: 199, 점수: 10.0\n",
      "n_buffer : 1929, eps : 9.0%\n",
      "에피소드: 299, 점수: 9.0\n",
      "n_buffer : 3069, eps : 8.5%\n",
      "에피소드: 399, 점수: 105.0\n",
      "n_buffer : 5810, eps : 8.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 500.0\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: CartPole-v1\n",
      "state space: (4,)\n",
      "action space: Discrete(2)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: 10.0\n",
      "n_buffer : 983, eps : 9.5%\n",
      "에피소드: 199, 점수: 10.0\n",
      "n_buffer : 1948, eps : 9.0%\n",
      "에피소드: 299, 점수: 12.0\n",
      "n_buffer : 2932, eps : 8.5%\n",
      "에피소드: 399, 점수: 12.0\n",
      "n_buffer : 4132, eps : 8.0%\n",
      "에피소드: 499, 점수: 190.0\n",
      "n_buffer : 7655, eps : 7.5%\n",
      "에피소드: 599, 점수: 351.0\n",
      "n_buffer : 30735, eps : 7.0%\n",
      "에피소드: 699, 점수: 220.0\n",
      "n_buffer : 50000, eps : 6.5%\n",
      "에피소드: 799, 점수: 167.0\n",
      "n_buffer : 50000, eps : 6.0%\n",
      "에피소드: 899, 점수: 157.0\n",
      "n_buffer : 50000, eps : 5.5%\n",
      "에피소드: 999, 점수: 170.0\n",
      "n_buffer : 50000, eps : 5.0%\n",
      "에피소드: 1099, 점수: 233.0\n",
      "n_buffer : 50000, eps : 4.5%\n",
      "에피소드: 1199, 점수: 135.0\n",
      "n_buffer : 50000, eps : 4.0%\n",
      "에피소드: 1299, 점수: 253.0\n",
      "n_buffer : 50000, eps : 3.5%\n",
      "에피소드: 1399, 점수: 407.0\n",
      "n_buffer : 50000, eps : 3.0%\n",
      "종료 조건 만족. 최종 5번 평균 점수 500.0\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: CartPole-v1\n",
      "state space: (4,)\n",
      "action space: Discrete(2)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: 9.0\n",
      "n_buffer : 1015, eps : 9.5%\n",
      "에피소드: 199, 점수: 11.0\n",
      "n_buffer : 2021, eps : 9.0%\n",
      "에피소드: 299, 점수: 9.0\n",
      "n_buffer : 3018, eps : 8.5%\n",
      "에피소드: 399, 점수: 15.0\n",
      "n_buffer : 4080, eps : 8.0%\n",
      "에피소드: 499, 점수: 89.0\n",
      "n_buffer : 7040, eps : 7.5%\n",
      "에피소드: 599, 점수: 215.0\n",
      "n_buffer : 19606, eps : 7.0%\n",
      "에피소드: 699, 점수: 154.0\n",
      "n_buffer : 36134, eps : 6.5%\n",
      "에피소드: 799, 점수: 351.0\n",
      "n_buffer : 50000, eps : 6.0%\n",
      "에피소드: 899, 점수: 139.0\n",
      "n_buffer : 50000, eps : 5.5%\n",
      "에피소드: 999, 점수: 228.0\n",
      "n_buffer : 50000, eps : 5.0%\n",
      "에피소드: 1099, 점수: 220.0\n",
      "n_buffer : 50000, eps : 4.5%\n",
      "에피소드: 1199, 점수: 210.0\n",
      "n_buffer : 50000, eps : 4.0%\n",
      "에피소드: 1299, 점수: 330.0\n",
      "n_buffer : 50000, eps : 3.5%\n",
      "에피소드: 1399, 점수: 157.0\n",
      "n_buffer : 50000, eps : 3.0%\n",
      "에피소드: 1499, 점수: 187.0\n",
      "n_buffer : 50000, eps : 2.5%\n",
      "에피소드: 1599, 점수: 500.0\n",
      "n_buffer : 50000, eps : 2.0%\n",
      "에피소드: 1699, 점수: 449.0\n",
      "n_buffer : 50000, eps : 1.5%\n",
      "에피소드: 1799, 점수: 101.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1899, 점수: 143.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1999, 점수: 232.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2099, 점수: 97.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2199, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2299, 점수: 161.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2399, 점수: 291.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2499, 점수: 128.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2599, 점수: 321.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2699, 점수: 394.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2799, 점수: 213.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2899, 점수: 292.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2999, 점수: 377.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3099, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3199, 점수: 143.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3299, 점수: 120.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3399, 점수: 24.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3499, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3599, 점수: 304.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3699, 점수: 272.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3799, 점수: 254.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3899, 점수: 334.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3999, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4099, 점수: 328.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4199, 점수: 233.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4299, 점수: 278.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "종료 조건 만족. 최종 10번 평균 점수 500.0\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: CartPole-v1\n",
      "state space: (4,)\n",
      "action space: Discrete(2)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: 8.0\n",
      "n_buffer : 1002, eps : 9.5%\n",
      "에피소드: 199, 점수: 12.0\n",
      "n_buffer : 1976, eps : 9.0%\n",
      "에피소드: 299, 점수: 10.0\n",
      "n_buffer : 3149, eps : 8.5%\n",
      "에피소드: 399, 점수: 17.0\n",
      "n_buffer : 4386, eps : 8.0%\n",
      "에피소드: 499, 점수: 185.0\n",
      "n_buffer : 20852, eps : 7.5%\n",
      "에피소드: 599, 점수: 189.0\n",
      "n_buffer : 38447, eps : 7.0%\n",
      "에피소드: 699, 점수: 214.0\n",
      "n_buffer : 50000, eps : 6.5%\n",
      "에피소드: 799, 점수: 104.0\n",
      "n_buffer : 50000, eps : 6.0%\n",
      "에피소드: 899, 점수: 175.0\n",
      "n_buffer : 50000, eps : 5.5%\n",
      "에피소드: 999, 점수: 122.0\n",
      "n_buffer : 50000, eps : 5.0%\n",
      "에피소드: 1099, 점수: 142.0\n",
      "n_buffer : 50000, eps : 4.5%\n",
      "에피소드: 1199, 점수: 177.0\n",
      "n_buffer : 50000, eps : 4.0%\n",
      "에피소드: 1299, 점수: 202.0\n",
      "n_buffer : 50000, eps : 3.5%\n",
      "에피소드: 1399, 점수: 203.0\n",
      "n_buffer : 50000, eps : 3.0%\n",
      "에피소드: 1499, 점수: 158.0\n",
      "n_buffer : 50000, eps : 2.5%\n",
      "에피소드: 1599, 점수: 190.0\n",
      "n_buffer : 50000, eps : 2.0%\n",
      "에피소드: 1699, 점수: 164.0\n",
      "n_buffer : 50000, eps : 1.5%\n",
      "에피소드: 1799, 점수: 139.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1899, 점수: 198.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1999, 점수: 104.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2099, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2199, 점수: 173.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2299, 점수: 313.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2399, 점수: 238.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2499, 점수: 165.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2599, 점수: 344.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2699, 점수: 122.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2799, 점수: 282.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2899, 점수: 264.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2999, 점수: 246.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3099, 점수: 267.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3199, 점수: 245.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3299, 점수: 246.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3399, 점수: 194.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3499, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3599, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3699, 점수: 462.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3799, 점수: 283.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "종료 조건 만족. 최종 20번 평균 점수 500.0\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DQN\n",
      "env: CartPole-v1\n",
      "state space: (4,)\n",
      "action space: Discrete(2)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: 30.0\n",
      "n_buffer : 5204, eps : 9.5%\n",
      "에피소드: 199, 점수: 182.0\n",
      "n_buffer : 16170, eps : 9.0%\n",
      "에피소드: 299, 점수: 187.0\n",
      "n_buffer : 25180, eps : 8.5%\n",
      "에피소드: 399, 점수: 131.0\n",
      "n_buffer : 40562, eps : 8.0%\n",
      "에피소드: 499, 점수: 173.0\n",
      "n_buffer : 50000, eps : 7.5%\n",
      "에피소드: 599, 점수: 179.0\n",
      "n_buffer : 50000, eps : 7.0%\n",
      "에피소드: 699, 점수: 199.0\n",
      "n_buffer : 50000, eps : 6.5%\n",
      "에피소드: 799, 점수: 298.0\n",
      "n_buffer : 50000, eps : 6.0%\n",
      "에피소드: 899, 점수: 356.0\n",
      "n_buffer : 50000, eps : 5.5%\n",
      "에피소드: 999, 점수: 150.0\n",
      "n_buffer : 50000, eps : 5.0%\n",
      "에피소드: 1099, 점수: 135.0\n",
      "n_buffer : 50000, eps : 4.5%\n",
      "에피소드: 1199, 점수: 280.0\n",
      "n_buffer : 50000, eps : 4.0%\n",
      "에피소드: 1299, 점수: 198.0\n",
      "n_buffer : 50000, eps : 3.5%\n",
      "에피소드: 1399, 점수: 165.0\n",
      "n_buffer : 50000, eps : 3.0%\n",
      "에피소드: 1499, 점수: 173.0\n",
      "n_buffer : 50000, eps : 2.5%\n",
      "에피소드: 1599, 점수: 109.0\n",
      "n_buffer : 50000, eps : 2.0%\n",
      "에피소드: 1699, 점수: 165.0\n",
      "n_buffer : 50000, eps : 1.5%\n",
      "에피소드: 1799, 점수: 459.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1899, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1999, 점수: 190.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2099, 점수: 161.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2199, 점수: 126.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2299, 점수: 160.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2399, 점수: 130.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2499, 점수: 10.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2599, 점수: 212.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2699, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2799, 점수: 119.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2899, 점수: 99.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2999, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3099, 점수: 109.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3199, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3299, 점수: 143.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3399, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3499, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3599, 점수: 275.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3699, 점수: 118.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3799, 점수: 237.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3899, 점수: 181.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3999, 점수: 331.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4099, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4199, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4299, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4399, 점수: 412.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4499, 점수: 184.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4599, 점수: 146.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4699, 점수: 224.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4799, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4899, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4999, 점수: 267.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5099, 점수: 97.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5199, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5299, 점수: 158.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5399, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5499, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5599, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5699, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5799, 점수: 286.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5899, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5999, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6099, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6199, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6299, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "종료 조건 만족. 최종 40번 평균 점수 500.0\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n"
     ]
    }
   ],
   "source": [
    "from env import Env\n",
    "from runner import RunnerParams\n",
    "\n",
    "def dqn_pole_train():\n",
    "    from algorithms.dqn import DQNParams\n",
    "    from algorithms.dqn_runner import DQNRunner\n",
    "    algo_param = DQNParams(buffer_limit=50000, n_train_start=2000,\n",
    "                            n_node=128, start_epsilon=0.1, learning_rate=0.0005,\n",
    "                            update_interval=40)\n",
    "    runner_param = RunnerParams(save_net=True, name_postfix=str(algo_param),\n",
    "                                target_score=500.0,\n",
    "                                check_interval=1, print_interval=100, \n",
    "                                max_video=100, video_record_interval=0,\n",
    "                                reward_scale=100.0)\n",
    "    DQNRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "\n",
    "\n",
    "def dqn_pole_load():\n",
    "    from algorithms.dqn import DQNParams\n",
    "    from algorithms.dqn_runner import DQNRunner\n",
    "    algo_param = DQNParams(buffer_limit=50000, n_train_start=2000,\n",
    "                            n_node=128, start_epsilon=0.1, learning_rate=0.0005,\n",
    "                            update_interval=40)\n",
    "    runner_param = RunnerParams(train=False,\n",
    "                                load_net=True, \n",
    "                                load_name='DQN-CartPole-v1-500.0-train=True-intvl=8-rwdscl=100.0-node=128-lRate=0.0001-gma=0.98-nBuf=50000-nBat=32-nStrt=4000-updIntvl=40-1634515414.pt',\n",
    "                                name_postfix=str(algo_param),\n",
    "                                target_score=999.0,\n",
    "                                max_video=3, \n",
    "                                check_interval=1, print_interval=1, video_record_interval=1,\n",
    "                                reward_scale=100.0,\n",
    "                                save_step_log=True)\n",
    "    DQNRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "\n",
    "dqn_pole_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: CartPole-v1\n",
      "state space: (4,)\n",
      "action space: Discrete(2)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: 32.0\n",
      "n_buffer : 3656, eps : 7.5%\n",
      "에피소드: 199, 점수: 151.0\n",
      "n_buffer : 8613, eps : 7.0%\n",
      "종료 조건 만족. 최종 1번 평균 점수 500.0\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: CartPole-v1\n",
      "state space: (4,)\n",
      "action space: Discrete(2)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: 9.0\n",
      "n_buffer : 973, eps : 7.5%\n",
      "에피소드: 199, 점수: 10.0\n",
      "n_buffer : 1966, eps : 7.0%\n",
      "에피소드: 299, 점수: 10.0\n",
      "n_buffer : 2931, eps : 6.5%\n",
      "에피소드: 399, 점수: 10.0\n",
      "n_buffer : 3895, eps : 6.0%\n",
      "에피소드: 499, 점수: 27.0\n",
      "n_buffer : 5272, eps : 5.5%\n",
      "에피소드: 599, 점수: 159.0\n",
      "n_buffer : 13199, eps : 5.0%\n",
      "에피소드: 699, 점수: 82.0\n",
      "n_buffer : 26506, eps : 4.5%\n",
      "에피소드: 799, 점수: 294.0\n",
      "n_buffer : 44939, eps : 4.0%\n",
      "에피소드: 899, 점수: 160.0\n",
      "n_buffer : 50000, eps : 3.5%\n",
      "에피소드: 999, 점수: 147.0\n",
      "n_buffer : 50000, eps : 3.0%\n",
      "에피소드: 1099, 점수: 408.0\n",
      "n_buffer : 50000, eps : 2.5%\n",
      "에피소드: 1199, 점수: 243.0\n",
      "n_buffer : 50000, eps : 2.0%\n",
      "에피소드: 1299, 점수: 132.0\n",
      "n_buffer : 50000, eps : 1.5%\n",
      "에피소드: 1399, 점수: 158.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1499, 점수: 145.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1599, 점수: 132.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1699, 점수: 115.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1799, 점수: 119.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1899, 점수: 204.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1999, 점수: 196.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2099, 점수: 255.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2199, 점수: 252.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2299, 점수: 199.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2399, 점수: 258.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2499, 점수: 156.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2599, 점수: 253.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2699, 점수: 396.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2799, 점수: 455.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2899, 점수: 316.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2999, 점수: 165.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3099, 점수: 158.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3199, 점수: 437.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3299, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "종료 조건 만족. 최종 5번 평균 점수 500.0\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: CartPole-v1\n",
      "state space: (4,)\n",
      "action space: Discrete(2)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: 8.0\n",
      "n_buffer : 957, eps : 7.5%\n",
      "에피소드: 199, 점수: 8.0\n",
      "n_buffer : 1928, eps : 7.0%\n",
      "에피소드: 299, 점수: 10.0\n",
      "n_buffer : 2888, eps : 6.5%\n",
      "에피소드: 399, 점수: 10.0\n",
      "n_buffer : 3848, eps : 6.0%\n",
      "에피소드: 499, 점수: 8.0\n",
      "n_buffer : 7161, eps : 5.5%\n",
      "에피소드: 599, 점수: 164.0\n",
      "n_buffer : 25376, eps : 5.0%\n",
      "에피소드: 699, 점수: 312.0\n",
      "n_buffer : 50000, eps : 4.5%\n",
      "에피소드: 799, 점수: 225.0\n",
      "n_buffer : 50000, eps : 4.0%\n",
      "에피소드: 899, 점수: 78.0\n",
      "n_buffer : 50000, eps : 3.5%\n",
      "에피소드: 999, 점수: 140.0\n",
      "n_buffer : 50000, eps : 3.0%\n",
      "에피소드: 1099, 점수: 242.0\n",
      "n_buffer : 50000, eps : 2.5%\n",
      "에피소드: 1199, 점수: 261.0\n",
      "n_buffer : 50000, eps : 2.0%\n",
      "에피소드: 1299, 점수: 25.0\n",
      "n_buffer : 50000, eps : 1.5%\n",
      "에피소드: 1399, 점수: 366.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1499, 점수: 192.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1599, 점수: 139.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1699, 점수: 259.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1799, 점수: 475.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1899, 점수: 234.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1999, 점수: 222.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2099, 점수: 309.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2199, 점수: 481.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2299, 점수: 242.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2399, 점수: 324.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2499, 점수: 366.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2599, 점수: 330.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2699, 점수: 165.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2799, 점수: 254.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2899, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "종료 조건 만족. 최종 10번 평균 점수 500.0\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: CartPole-v1\n",
      "state space: (4,)\n",
      "action space: Discrete(2)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: 13.0\n",
      "n_buffer : 1389, eps : 7.5%\n",
      "에피소드: 199, 점수: 10.0\n",
      "n_buffer : 2762, eps : 7.0%\n",
      "에피소드: 299, 점수: 10.0\n",
      "n_buffer : 4115, eps : 6.5%\n",
      "에피소드: 399, 점수: 9.0\n",
      "n_buffer : 6012, eps : 6.0%\n",
      "에피소드: 499, 점수: 215.0\n",
      "n_buffer : 28883, eps : 5.5%\n",
      "에피소드: 599, 점수: 264.0\n",
      "n_buffer : 50000, eps : 5.0%\n",
      "에피소드: 699, 점수: 251.0\n",
      "n_buffer : 50000, eps : 4.5%\n",
      "에피소드: 799, 점수: 197.0\n",
      "n_buffer : 50000, eps : 4.0%\n",
      "에피소드: 899, 점수: 328.0\n",
      "n_buffer : 50000, eps : 3.5%\n",
      "에피소드: 999, 점수: 445.0\n",
      "n_buffer : 50000, eps : 3.0%\n",
      "에피소드: 1099, 점수: 149.0\n",
      "n_buffer : 50000, eps : 2.5%\n",
      "에피소드: 1199, 점수: 102.0\n",
      "n_buffer : 50000, eps : 2.0%\n",
      "에피소드: 1299, 점수: 116.0\n",
      "n_buffer : 50000, eps : 1.5%\n",
      "에피소드: 1399, 점수: 264.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1499, 점수: 186.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1599, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1699, 점수: 193.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1799, 점수: 177.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1899, 점수: 410.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1999, 점수: 306.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2099, 점수: 201.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2199, 점수: 179.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2299, 점수: 176.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2399, 점수: 18.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2499, 점수: 365.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2599, 점수: 281.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2699, 점수: 419.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2799, 점수: 272.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2899, 점수: 39.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2999, 점수: 270.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3099, 점수: 263.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3199, 점수: 195.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3299, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3399, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3499, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3599, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3699, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3799, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3899, 점수: 123.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3999, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4099, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4199, 점수: 143.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4299, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4399, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4499, 점수: 197.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4599, 점수: 111.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4699, 점수: 259.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4799, 점수: 197.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4899, 점수: 302.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4999, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5099, 점수: 140.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5199, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5299, 점수: 149.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5399, 점수: 381.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5499, 점수: 278.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5599, 점수: 442.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5699, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5799, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5899, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5999, 점수: 188.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6099, 점수: 235.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6199, 점수: 234.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6299, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6399, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6499, 점수: 117.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6599, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6699, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6799, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6899, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6999, 점수: 178.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 7099, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 7199, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "종료 조건 만족. 최종 20번 평균 점수 500.0\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n",
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: CartPole-v1\n",
      "state space: (4,)\n",
      "action space: Discrete(2)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: 9.0\n",
      "n_buffer : 961, eps : 7.5%\n",
      "에피소드: 199, 점수: 9.0\n",
      "n_buffer : 1945, eps : 7.0%\n",
      "에피소드: 299, 점수: 9.0\n",
      "n_buffer : 2930, eps : 6.5%\n",
      "에피소드: 399, 점수: 12.0\n",
      "n_buffer : 3900, eps : 6.0%\n",
      "에피소드: 499, 점수: 12.0\n",
      "n_buffer : 5068, eps : 5.5%\n",
      "에피소드: 599, 점수: 160.0\n",
      "n_buffer : 16873, eps : 5.0%\n",
      "에피소드: 699, 점수: 148.0\n",
      "n_buffer : 37899, eps : 4.5%\n",
      "에피소드: 799, 점수: 179.0\n",
      "n_buffer : 50000, eps : 4.0%\n",
      "에피소드: 899, 점수: 159.0\n",
      "n_buffer : 50000, eps : 3.5%\n",
      "에피소드: 999, 점수: 110.0\n",
      "n_buffer : 50000, eps : 3.0%\n",
      "에피소드: 1099, 점수: 183.0\n",
      "n_buffer : 50000, eps : 2.5%\n",
      "에피소드: 1199, 점수: 161.0\n",
      "n_buffer : 50000, eps : 2.0%\n",
      "에피소드: 1299, 점수: 184.0\n",
      "n_buffer : 50000, eps : 1.5%\n",
      "에피소드: 1399, 점수: 182.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1499, 점수: 310.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1599, 점수: 197.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1699, 점수: 468.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1799, 점수: 155.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1899, 점수: 294.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 1999, 점수: 466.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2099, 점수: 155.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2199, 점수: 204.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2299, 점수: 210.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2399, 점수: 259.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2499, 점수: 337.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2599, 점수: 140.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2699, 점수: 243.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2799, 점수: 350.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2899, 점수: 225.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 2999, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3099, 점수: 471.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3199, 점수: 293.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3299, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3399, 점수: 98.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3499, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3599, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3699, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3799, 점수: 215.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3899, 점수: 124.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 3999, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4099, 점수: 157.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4199, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4299, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4399, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4499, 점수: 167.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4599, 점수: 289.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4699, 점수: 213.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4799, 점수: 264.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4899, 점수: 250.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 4999, 점수: 176.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5099, 점수: 169.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5199, 점수: 130.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5299, 점수: 186.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5399, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5499, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5599, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5699, 점수: 223.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5799, 점수: 339.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5899, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 5999, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6099, 점수: 28.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6199, 점수: 390.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6299, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6399, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6499, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6599, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6699, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6799, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6899, 점수: 206.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 6999, 점수: 131.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 7099, 점수: 246.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 7199, 점수: 237.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 7299, 점수: 244.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 7399, 점수: 230.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 7499, 점수: 245.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 7599, 점수: 235.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 7699, 점수: 230.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 7799, 점수: 238.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 7899, 점수: 242.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 7999, 점수: 328.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 8099, 점수: 12.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 8199, 점수: 124.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 8299, 점수: 216.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 8399, 점수: 395.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 8499, 점수: 430.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 8599, 점수: 496.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 8699, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 8799, 점수: 467.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 8899, 점수: 329.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "에피소드: 8999, 점수: 500.0\n",
      "n_buffer : 50000, eps : 1.0%\n",
      "종료 조건 만족. 최종 40번 평균 점수 500.0\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n"
     ]
    }
   ],
   "source": [
    "from env import Env\n",
    "from runner import RunnerParams\n",
    "\n",
    "def ddqn_pole_train():\n",
    "    from algorithms.ddqn import DDQNParams\n",
    "    from algorithms.ddqn_runner import DDQNRunner\n",
    "    algo_param = DDQNParams(buffer_limit=50000, n_train_start=4000,\n",
    "                            batch_size=32, gamma=0.98,\n",
    "                            n_node=128, start_epsilon=0.08, learning_rate=0.0005,\n",
    "                            update_interval=20)\n",
    "    runner_param = RunnerParams(save_net=True, name_postfix=str(algo_param),\n",
    "                                target_score=500.0,\n",
    "                                check_interval=1, print_interval=100,  \n",
    "                                max_video=100, video_record_interval=0,\n",
    "                                reward_scale=100.0)\n",
    "    runner_param.check_interval = 1\n",
    "    DDQNRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval = 5\n",
    "    DDQNRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval = 10\n",
    "    DDQNRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval = 20\n",
    "    DDQNRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval = 40\n",
    "    DDQNRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "\n",
    "\n",
    "def ddqn_pole_load():\n",
    "    from algorithms.ddqn import DDQNParams\n",
    "    from algorithms.ddqn_runner import DDQNRunner\n",
    "    algo_param = DDQNParams(buffer_limit=50000, n_train_start=2000,\n",
    "                            batch_size=32, gamma=0.98,\n",
    "                            n_node=128, start_epsilon=0.08, learning_rate=0.0005,\n",
    "                            update_interval=20)\n",
    "    runner_param = RunnerParams(train=False,\n",
    "                                load_net=True, \n",
    "                                load_name='DDQN-CartPole-v1-500.0-train=True-intvl=10-rwdscl=100.0-node=128-lRate=0.0005-gma=0.98-nBuf=50000-nBat=32-nStrt=2000-updIntvl=20-1634511724.pt',\n",
    "                                name_postfix=str(algo_param),\n",
    "                                target_score=999.0,\n",
    "                                max_video=3, \n",
    "                                check_interval=1, video_record_interval=1,\n",
    "                                reward_scale=100.0,\n",
    "                                save_step_log=True)\n",
    "    DDQNRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "\n",
    "ddqn_pole_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 설정\n",
      "algorithm: ActorCritic\n",
      "env: CartPole-v1\n",
      "state space: (4,)\n",
      "action space: Discrete(2)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: 14.0\n",
      "에피소드: 199, 점수: 47.0\n",
      "에피소드: 299, 점수: 136.0\n",
      "에피소드: 399, 점수: 80.0\n",
      "에피소드: 499, 점수: 210.0\n",
      "종료 조건 만족. 최종 1번 평균 점수 500.0\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n",
      "초기 설정\n",
      "algorithm: ActorCritic\n",
      "env: CartPole-v1\n",
      "state space: (4,)\n",
      "action space: Discrete(2)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: 19.0\n",
      "에피소드: 199, 점수: 28.0\n",
      "에피소드: 299, 점수: 37.0\n",
      "에피소드: 399, 점수: 130.0\n",
      "에피소드: 499, 점수: 55.0\n",
      "에피소드: 599, 점수: 219.0\n",
      "에피소드: 699, 점수: 420.0\n",
      "에피소드: 799, 점수: 500.0\n",
      "종료 조건 만족. 최종 5번 평균 점수 500.0\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n",
      "초기 설정\n",
      "algorithm: ActorCritic\n",
      "env: CartPole-v1\n",
      "state space: (4,)\n",
      "action space: Discrete(2)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: 15.0\n",
      "에피소드: 199, 점수: 13.0\n",
      "에피소드: 299, 점수: 23.0\n",
      "에피소드: 399, 점수: 24.0\n",
      "에피소드: 499, 점수: 51.0\n",
      "에피소드: 599, 점수: 202.0\n",
      "에피소드: 699, 점수: 171.0\n",
      "에피소드: 799, 점수: 251.0\n",
      "에피소드: 899, 점수: 259.0\n",
      "에피소드: 999, 점수: 436.0\n",
      "에피소드: 1099, 점수: 198.0\n",
      "에피소드: 1199, 점수: 225.0\n",
      "에피소드: 1299, 점수: 233.0\n",
      "에피소드: 1399, 점수: 500.0\n",
      "종료 조건 만족. 최종 10번 평균 점수 500.0\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n",
      "초기 설정\n",
      "algorithm: ActorCritic\n",
      "env: CartPole-v1\n",
      "state space: (4,)\n",
      "action space: Discrete(2)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: 13.0\n",
      "에피소드: 199, 점수: 26.0\n",
      "에피소드: 299, 점수: 27.0\n",
      "에피소드: 399, 점수: 126.0\n",
      "에피소드: 499, 점수: 120.0\n",
      "에피소드: 599, 점수: 288.0\n",
      "에피소드: 699, 점수: 500.0\n",
      "에피소드: 799, 점수: 235.0\n",
      "에피소드: 899, 점수: 162.0\n",
      "에피소드: 999, 점수: 384.0\n",
      "에피소드: 1099, 점수: 385.0\n",
      "에피소드: 1199, 점수: 272.0\n",
      "에피소드: 1299, 점수: 500.0\n",
      "에피소드: 1399, 점수: 500.0\n",
      "종료 조건 만족. 최종 20번 평균 점수 500.0\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n",
      "초기 설정\n",
      "algorithm: ActorCritic\n",
      "env: CartPole-v1\n",
      "state space: (4,)\n",
      "action space: Discrete(2)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: 52.0\n",
      "에피소드: 199, 점수: 73.0\n",
      "에피소드: 299, 점수: 34.0\n",
      "에피소드: 399, 점수: 188.0\n",
      "에피소드: 499, 점수: 143.0\n",
      "에피소드: 599, 점수: 475.0\n",
      "에피소드: 699, 점수: 309.0\n",
      "에피소드: 799, 점수: 350.0\n",
      "에피소드: 899, 점수: 500.0\n",
      "종료 조건 만족. 최종 40번 평균 점수 500.0\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n"
     ]
    }
   ],
   "source": [
    "from env import Env\n",
    "from runner import RunnerParams\n",
    "\n",
    "def ac_pole_train():\n",
    "    from algorithms.actorcritic import ActorCriticParams\n",
    "    from algorithms.actorcritic_runner import ActorCriticRunner\n",
    "    algo_param = ActorCriticParams(n_node=256, learning_rate=0.0002,\n",
    "                                    gamma=0.98, n_rollout=10)\n",
    "    runner_param = RunnerParams(save_net=True, name_postfix=str(algo_param),\n",
    "                                target_score=500.0,\n",
    "                                check_interval=1, print_interval=100,  \n",
    "                                max_video=100, video_record_interval=0,\n",
    "                                reward_scale=100.0)\n",
    "    runner_param.check_interval = 1\n",
    "    ActorCriticRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval = 5\n",
    "    ActorCriticRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval = 10\n",
    "    ActorCriticRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval = 20\n",
    "    ActorCriticRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval = 40\n",
    "    ActorCriticRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "\n",
    "\n",
    "def ac_pole_load():\n",
    "    from algorithms.actorcritic import ActorCriticParams\n",
    "    from algorithms.actorcritic_runner import ActorCriticRunner\n",
    "    algo_param = ActorCriticParams(n_node=256, learning_rate=0.0002,\n",
    "                                    gamma=0.98, n_rollout=10)\n",
    "    runner_param = RunnerParams(train=False,\n",
    "                                load_net=True, \n",
    "                                load_name='ActorCritic-CartPole-v1-500.0-train=True-intvl=8-rwdscl=100.0-node=256-lRate=0.0002-gma=0.98-nRoll=10-1634510799.pt',\n",
    "                                name_postfix=str(algo_param),\n",
    "                                target_score=999.0,\n",
    "                                max_video=3, \n",
    "                                check_interval=1, video_record_interval=1,\n",
    "                                reward_scale=100.0,\n",
    "                                save_step_log=True)\n",
    "    ActorCriticRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "\n",
    "ac_pole_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import Env\n",
    "from runner import RunnerParams\n",
    "\n",
    "def rein_pole_train():\n",
    "    from algorithms.reinfoce import ReinforceParams\n",
    "    from algorithms.reinforce_runner import ReinforceRunner\n",
    "    algo_param = ReinforceParams()\n",
    "    runner_param = RunnerParams(save_net=True, name_postfix=str(algo_param),\n",
    "                                target_score=500.0,\n",
    "                                check_interval=1, print_interval=100, \n",
    "                                max_video=100, video_record_interval=0,\n",
    "                                reward_scale=100.0)\n",
    "    runner_param.check_interval = 1\n",
    "    ReinforceRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval = 5\n",
    "    ReinforceRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval = 10\n",
    "    ReinforceRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval = 20\n",
    "    ReinforceRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval = 40\n",
    "    ReinforceRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "\n",
    "def rein_pole_load():\n",
    "    from algorithms.reinfoce import ReinforceParams\n",
    "    from algorithms.reinforce_runner import ReinforceRunner\n",
    "    algo_param = ReinforceParams()\n",
    "    runner_param = RunnerParams(train=False,\n",
    "                                load_net=True, \n",
    "                                load_name='',\n",
    "                                name_postfix=str(algo_param),\n",
    "                                target_score=999.0,\n",
    "                                max_video=3, \n",
    "                                check_interval=1, video_record_interval=1,\n",
    "                                reward_scale=100.0,\n",
    "                                save_step_log=True)\n",
    "    ReinforceRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "\n",
    "rein_pole_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ppo_pole_train():\n",
    "#     from algorithms.ppo import PPOParams\n",
    "#     from algorithms.ppo_runner import PPORunner\n",
    "#     algo_param = PPOParams(n_node=128, learning_rate=0.0001, \n",
    "#                             gamma=0.98, lmbda=0.95, eps_clip=0.1, \n",
    "#                             k_epoch=3, t_horizon=20)\n",
    "#     runner_param = RunnerParams(save_net=True, name_postfix=str(algo_param),\n",
    "#                                 target_score=500.0,\n",
    "#                                 interval=100, \n",
    "#                                 max_video=100, video_record_interval=200,\n",
    "#                                 reward_scale=100.0)\n",
    "#     PPORunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "\n",
    "\n",
    "# def ppo_pole_load():\n",
    "#     from algorithms.ppo import PPOParams\n",
    "#     from algorithms.ppo_runner import PPORunner\n",
    "#     algo_param = PPOParams(n_node=128, learning_rate=0.0001, \n",
    "#                             gamma=0.98, lmbda=0.95, eps_clip=0.1, \n",
    "#                             k_epoch=3, t_horizon=20)\n",
    "#     runner_param = RunnerParams(train=False,\n",
    "#                                 load_net=True, \n",
    "#                                 load_name='PPO-CartPole-v1-500.0-train=True-intvl=100-rwdscl=100.0-node=128-lRate=0.0001-gma=0.98-lmb=0.95-epsclp=0.1-k=3-t=20-1632243563.pt',\n",
    "#                                 name_postfix=str(algo_param),\n",
    "#                                 target_score=999.0,\n",
    "#                                 max_video=100, \n",
    "#                                 interval=1, video_record_interval=1,\n",
    "#                                 reward_scale=100.0)\n",
    "#     PPORunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "\n",
    "\n",
    "# def ppolstm_pole_train():\n",
    "#     from algorithms.ppolstm import PPOlstmParams\n",
    "#     from algorithms.ppolstm_runner import PPOlstmRunner\n",
    "#     algo_param = PPOlstmParams(n_node=128, learning_rate=0.0001, \n",
    "#                                 gamma=0.98, lmbda=0.95, \n",
    "#                                 eps_clip=0.1, k_epoch=3, t_horizon=20)\n",
    "#     runner_param = RunnerParams(save_net=True, name_postfix=str(algo_param),\n",
    "#                                 target_score=500.0,\n",
    "#                                 interval=32, \n",
    "#                                 max_video=100, video_record_interval=200,\n",
    "#                                 reward_scale=100.0)\n",
    "#     PPOlstmRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n",
    "\n",
    "\n",
    "# def ppolstm_pole_load():\n",
    "#     from algorithms.ppolstm import PPOlstmParams\n",
    "#     from algorithms.ppolstm_runner import PPOlstmRunner\n",
    "#     algo_param = PPOlstmParams(n_node=128, learning_rate=0.0001, \n",
    "#                                 gamma=0.98, lmbda=0.95, \n",
    "#                                 eps_clip=0.1, k_epoch=3, t_horizon=20)\n",
    "#     runner_param = RunnerParams(train=False,\n",
    "#                                 load_net=True, \n",
    "#                                 load_name='PPOlstm-CartPole-v1-500.0-train=True-intvl=32-rwdscl=100.0-node=128-lRate=0.0001-gma=0.98-lmb=0.95-epsclp=0.1-k=3-t=20-1632245913.pt',\n",
    "#                                 name_postfix=str(algo_param),\n",
    "#                                 target_score=999.0,\n",
    "#                                 max_video=100, \n",
    "#                                 interval=1, video_record_interval=1,\n",
    "#                                 reward_scale=100.0)\n",
    "#     PPOlstmRunner(Env.CARTPOLE.value, algo_param, runner_param).run()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92bb61e8f2b0dcdaa21cd71aad1d97e3da046ad8a677ac321cbd25d595832889"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('py38-pytorch-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
