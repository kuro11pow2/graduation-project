{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "run anaconda prompt \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "home_path = os.path.expanduser('~')\n",
    "cur_path = os.getcwd()\n",
    "conda_path = home_path + \"\\\\anaconda3\"\n",
    "conda_script_path = home_path + \"\\\\anaconda3\\\\Scripts\\\\activate.bat\"\n",
    "exc = ' '.join(['start', '%windir%\\System32\\cmd.exe \"/K\"', conda_script_path, conda_path])\n",
    "!$exc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "run tensorboard server\n",
    "\n",
    "conda activate py38-pytorch-gpu && tensorboard --port=6006 --logdir=runs\n",
    "http://localhost:6006/\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "print env info\n",
    "\n",
    "긴 경로 제한 해제\n",
    "https://docs.microsoft.com/ko-kr/windows/win32/fileio/maximum-file-path-limitation?tabs=powershell\n",
    "\"\"\"\n",
    "\n",
    "import gym\n",
    "from env import Env\n",
    "\n",
    "env = gym.make(Env.BIPEDALWALKER.value)\n",
    "\n",
    "print(dir(env))\n",
    "print(f'{env._max_episode_steps=}')\n",
    "print(f'{env.action_space=}')\n",
    "print(f'{env.metadata=}')\n",
    "print(f'{env.observation_space.shape[0]=}')\n",
    "print(f'{env.reward_range=}')\n",
    "print(f'{env.seed=}')\n",
    "print(f'{env.spec=}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import Env\n",
    "from runner import RunnerParams\n",
    "\n",
    "def dqn_lander_train():\n",
    "    from algorithms.dqn import DQNParams\n",
    "    from algorithms.dqn_runner import DQNRunner\n",
    "    algo_param = DQNParams(buffer_limit=100000, n_train_start=10000,\n",
    "                            n_node=512, start_epsilon=0.2, learning_rate=0.0005,\n",
    "                            update_interval=20, batch_size=64)\n",
    "    runner_param = RunnerParams(save_net=True, name_postfix=str(algo_param),\n",
    "                                target_score=200.0,\n",
    "                                check_interval=None, print_interval=100, \n",
    "                                max_video=100, video_record_interval=0,\n",
    "                                reward_scale=30.0)\n",
    "    runner_param.check_interval = 1\n",
    "    DQNRunner(Env.LUNARLANDER.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval = 5\n",
    "    DQNRunner(Env.LUNARLANDER.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval = 10\n",
    "    DQNRunner(Env.LUNARLANDER.value, algo_param, runner_param).run()\n",
    "\n",
    "\n",
    "def dqn_lander_load():\n",
    "    from algorithms.dqn import DQNParams\n",
    "    from algorithms.dqn_runner import DQNRunner\n",
    "    algo_param = DQNParams(buffer_limit=100000, n_train_start=10000,\n",
    "                            n_node=512, start_epsilon=0.2, learning_rate=0.0005,\n",
    "                            update_interval=20, batch_size=64)\n",
    "    runner_param = RunnerParams(train=False,\n",
    "                                load_net=True, \n",
    "                                load_name='DQN-LunarLander-v2-202-train=True-intvl=10-rwdscl=30.0-node=512-lRate=0.0005-gma=0.98-nBuf=100000-nBat=64-nStrt=10000-updIntvl=20-1634576744.pt',\n",
    "                                name_postfix=str(algo_param),\n",
    "                                target_score=400.0,\n",
    "                                max_video=10, \n",
    "                                check_interval=1, print_interval=1, video_record_interval=1,\n",
    "                                reward_scale=30.0,\n",
    "                                save_step_log=True)\n",
    "    DQNRunner(Env.LUNARLANDER.value, algo_param, runner_param).run()\n",
    "\n",
    "dqn_lander_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 설정\n",
      "algorithm: DDQN\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "시뮬레이션 시작\n",
      "에피소드: 99, 점수: -99.4\n",
      "n_buffer : 12047, eps : 19.5%\n",
      "에피소드: 199, 점수: -27.1\n",
      "n_buffer : 33481, eps : 19.0%\n",
      "에피소드: 299, 점수: -135.1\n",
      "n_buffer : 62247, eps : 18.5%\n",
      "에피소드: 399, 점수: -332.3\n",
      "n_buffer : 100000, eps : 18.0%\n",
      "에피소드: 499, 점수: -42.6\n",
      "n_buffer : 100000, eps : 17.5%\n",
      "에피소드: 599, 점수: -80.1\n",
      "n_buffer : 100000, eps : 17.0%\n",
      "에피소드: 699, 점수: -91.7\n",
      "n_buffer : 100000, eps : 16.5%\n",
      "에피소드: 799, 점수: -7.8\n",
      "n_buffer : 100000, eps : 16.0%\n",
      "에피소드: 899, 점수: -82.4\n",
      "n_buffer : 100000, eps : 15.5%\n",
      "에피소드: 999, 점수: -46.4\n",
      "n_buffer : 100000, eps : 15.0%\n",
      "에피소드: 1099, 점수: 4.5\n",
      "n_buffer : 100000, eps : 14.5%\n",
      "에피소드: 1199, 점수: 189.7\n",
      "n_buffer : 100000, eps : 14.0%\n",
      "에피소드: 1299, 점수: 199.5\n",
      "n_buffer : 100000, eps : 13.5%\n",
      "에피소드: 1399, 점수: 178.0\n",
      "n_buffer : 100000, eps : 13.0%\n",
      "에피소드: 1499, 점수: 160.9\n",
      "n_buffer : 100000, eps : 12.5%\n",
      "에피소드: 1599, 점수: 230.9\n",
      "n_buffer : 100000, eps : 12.0%\n",
      "에피소드: 1699, 점수: 248.5\n",
      "n_buffer : 100000, eps : 11.5%\n",
      "종료 조건 만족. 최종 10번 평균 점수 218.94680779147217\n",
      "시뮬레이션 종료\n",
      "네트워크 저장\n"
     ]
    }
   ],
   "source": [
    "from env import Env\n",
    "from runner import RunnerParams\n",
    "\n",
    "def ddqn_lander_train():\n",
    "    from algorithms.ddqn import DDQNParams\n",
    "    from algorithms.ddqn_runner import DDQNRunner\n",
    "    algo_param = DDQNParams(buffer_limit=100000, n_train_start=10000,\n",
    "                            n_node=512, start_epsilon=0.2, learning_rate=0.0005,\n",
    "                            update_interval=20, batch_size=64)\n",
    "    runner_param = RunnerParams(save_net=True, name_postfix=str(algo_param),\n",
    "                                target_score=200.0,\n",
    "                                check_interval=None, print_interval=100, \n",
    "                                max_video=100, video_record_interval=0,\n",
    "                                reward_scale=30.0)\n",
    "    runner_param.check_interval = 10\n",
    "    DDQNRunner(Env.LUNARLANDER.value, algo_param, runner_param).run()\n",
    "\n",
    "\n",
    "def ddqn_lander_load():\n",
    "    from algorithms.ddqn import DDQNParams\n",
    "    from algorithms.ddqn_runner import DDQNRunner\n",
    "    algo_param = DDQNParams(buffer_limit=100000, n_train_start=10000,\n",
    "                            n_node=512, start_epsilon=0.2, learning_rate=0.0005,\n",
    "                            update_interval=20, batch_size=64)\n",
    "    runner_param = RunnerParams(train=False,\n",
    "                                load_net=True, \n",
    "                                load_name='DDQN-LunarLander-v2-218-train=True-intvl=10-rwdscl=30.0-node=512-lRate=0.0005-gma=0.98-nBuf=100000-nBat=64-nStrt=10000-updIntvl=20-1634584535.pt',\n",
    "                                name_postfix=str(algo_param),\n",
    "                                target_score=999.0,\n",
    "                                max_video=3, \n",
    "                                check_interval=1, video_record_interval=1,\n",
    "                                reward_scale=100.0,\n",
    "                                save_step_log=True)\n",
    "    DDQNRunner(Env.LUNARLANDER.value, algo_param, runner_param).run()\n",
    "\n",
    "ddqn_lander_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 설정\n",
      "algorithm: ActorCritic\n",
      "env: LunarLander-v2\n",
      "state space: (8,)\n",
      "action space: Discrete(4)\n",
      "네트워크 불러오기\n",
      "시뮬레이션 시작\n",
      "n_epi=0, self._score=311.61124857589016 비디오 저장\n",
      "n_epi=1, self._score=76.03180868367241 비디오 저장\n",
      "n_epi=2, self._score=297.30560035302506 비디오 저장\n",
      "n_epi=3, self._score=242.24781444601388 비디오 저장\n",
      "n_epi=4, self._score=250.56240293390945 비디오 저장\n",
      "n_epi=5, self._score=248.696982714693 비디오 저장\n",
      "n_epi=6, self._score=117.44151914704133 비디오 저장\n",
      "n_epi=7, self._score=134.43314261644574 비디오 저장\n",
      "n_epi=8, self._score=261.0641366370211 비디오 저장\n",
      "n_epi=9, self._score=252.71842285151777 비디오 저장\n",
      "종료 조건 만족. 최종 1번 평균 점수 252.71842285151777\n",
      "시뮬레이션 종료\n"
     ]
    }
   ],
   "source": [
    "from env import Env\n",
    "from runner import RunnerParams\n",
    "\n",
    "def ac_lunar_train():\n",
    "    from algorithms.actorcritic import ActorCriticParams\n",
    "    from algorithms.actorcritic_runner import ActorCriticRunner\n",
    "    algo_param = ActorCriticParams(n_node=256, learning_rate=0.002,\n",
    "                                    gamma=0.98, n_rollout=20)\n",
    "    runner_param = RunnerParams(save_net=True, name_postfix=str(algo_param),\n",
    "                                target_score=200.0,\n",
    "                                check_interval=None, print_interval=100, \n",
    "                                max_video=100, video_record_interval=0,\n",
    "                                reward_scale=30.0)\n",
    "    runner_param.check_interval=1\n",
    "    ActorCriticRunner(Env.LUNARLANDER.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval=5\n",
    "    ActorCriticRunner(Env.LUNARLANDER.value, algo_param, runner_param).run()\n",
    "    runner_param.check_interval=10\n",
    "    ActorCriticRunner(Env.LUNARLANDER.value, algo_param, runner_param).run()\n",
    "\n",
    "\n",
    "def ac_lunar_load():\n",
    "    from algorithms.actorcritic import ActorCriticParams\n",
    "    from algorithms.actorcritic_runner import ActorCriticRunner\n",
    "    algo_param = ActorCriticParams(n_node=256, learning_rate=0.002,\n",
    "                                    gamma=0.98, n_rollout=20)\n",
    "    runner_param = RunnerParams(train=False,\n",
    "                                load_net=True, \n",
    "                                load_name='ActorCritic-LunarLander-v2-247-train=True-intvl=5-rwdscl=30.0-node=256-lRate=0.002-gma=0.98-nRoll=10-1634590684.pt',\n",
    "                                name_postfix=str(algo_param),\n",
    "                                target_score=999.0,\n",
    "                                max_video=10, \n",
    "                                check_interval=1, video_record_interval=1,\n",
    "                                reward_scale=30.0,\n",
    "                                save_step_log=True)\n",
    "    ActorCriticRunner(Env.LUNARLANDER.value, algo_param, runner_param).run()\n",
    "\n",
    "ac_lunar_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ddqn lunar-lander\n",
    "# from env import Env\n",
    "# from runner import RunnerParams\n",
    "# from algorithms.ddqn import DDQNParams\n",
    "# from algorithms.ddqn_runner import DDQNRunner\n",
    "\n",
    "# runner_param = RunnerParams(save_net=True,\n",
    "#                             train=True,\n",
    "#                             target_score=200, \n",
    "#                             reward_scale=30.0, max_video=100, video_record_interval=200,\n",
    "#                             step_wrapper=lambda x: x)\n",
    "# algo_param = DDQNParams(n_node=512, batch_size=64, buffer_limit=50000, \n",
    "#                         n_train_start=4000, start_epsilon=0.2,\n",
    "#                         update_interval=20)\n",
    "# DDQNRunner(Env.LUNARLANDER.value, algo_param, runner_param).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ddqn lunar-lander 불러오기\n",
    "\n",
    "# from env import Env\n",
    "# from runner import RunnerParams\n",
    "# from algorithms.ddqn import DDQNParams\n",
    "# from algorithms.ddqn_runner import DDQNRunner\n",
    "\n",
    "# runner_param = RunnerParams(save_net=False, load_net=True, load_name='node512-score213-DDQN-LunarLander-v2-1631750946.pt',\n",
    "#                             train=False,\n",
    "#                             target_score=200, \n",
    "#                             reward_scale=30.0, max_video=100, video_record_interval=1,\n",
    "#                             step_wrapper=lambda x: x)\n",
    "# algo_param = DDQNParams(n_node=512, batch_size=64, buffer_limit=50000, \n",
    "#                         n_train_start=4000, start_epsilon=0.2,\n",
    "#                         update_interval=20)\n",
    "# DDQNRunner(Env.LUNARLANDER.value, algo_param, runner_param).run()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "92bb61e8f2b0dcdaa21cd71aad1d97e3da046ad8a677ac321cbd25d595832889"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 64-bit ('py38-pytorch-gpu': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
