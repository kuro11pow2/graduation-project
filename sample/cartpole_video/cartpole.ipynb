{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('py38-pytorch-gpu': conda)",
   "metadata": {
    "interpreter": {
     "hash": "92bb61e8f2b0dcdaa21cd71aad1d97e3da046ad8a677ac321cbd25d595832889"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 주의사항\n",
    "1. windows 환경에서는 빌드된 ffmpeg 실행파일을 환경 변수 > Path 에 등록해야 한다.\n",
    "2. gym 0.18.0 에는 video로 저장할 수 없는 버그가 있다. [링크](https://github.com/openai/gym/issues/1925)\n",
    "\n",
    "[참조](https://wegonnamakeit.tistory.com/59)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "from gym import wrappers\n",
    "from IPython.display import Video\n",
    "\n",
    "import collections\n",
    "import random\n",
    "\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "#Hyberparameters\n",
    "learning_rate = 0.0005\n",
    "gamma = 0.98\n",
    "buffer_limit = 50000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self):\n",
    "        self.buffer = collections.deque(maxlen=buffer_limit)\n",
    "    \n",
    "    def put(self, transition):\n",
    "        self.buffer.append(transition)\n",
    "    \n",
    "    def sample(self, n):\n",
    "        mini_batch = random.sample(self.buffer, n)\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_mask_lst = [], [], [], [], []\n",
    "        \n",
    "        for transition in mini_batch:\n",
    "            s, a, r, s_prime, done_mask = transition\n",
    "            s_lst.append(s)\n",
    "            a_lst.append([a])\n",
    "            r_lst.append([r])\n",
    "            s_prime_lst.append(s_prime)\n",
    "            done_mask_lst.append([done_mask])\n",
    "\n",
    "        return torch.tensor(s_lst, dtype=torch.float), torch.tensor(a_lst), \\\n",
    "               torch.tensor(r_lst), torch.tensor(s_prime_lst, dtype=torch.float), \\\n",
    "               torch.tensor(done_mask_lst)\n",
    "    \n",
    "    def size(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Qnet, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "      \n",
    "    def sample_action(self, obs, epsilon):\n",
    "        out = self.forward(obs)\n",
    "        coin = random.random()\n",
    "        if coin < epsilon:\n",
    "            return random.randint(0,1)\n",
    "        else : \n",
    "            return out.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(q, q_target, memory, optimizer):\n",
    "    for i in range(10):\n",
    "        s,a,r,s_prime,done_mask = memory.sample(batch_size)\n",
    "\n",
    "        q_out = q(s)\n",
    "        q_a = q_out.gather(1,a)\n",
    "        max_q_prime = q_target(s_prime).max(1)[0].unsqueeze(1)\n",
    "        target = r + gamma * max_q_prime * done_mask\n",
    "        loss = F.smooth_l1_loss(q_a, target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "n_episode :20, score : 10.2, n_buffer : 205, eps : 7.9%\n",
      "n_episode :40, score : 9.7, n_buffer : 398, eps : 7.8%\n",
      "n_episode :60, score : 9.9, n_buffer : 597, eps : 7.7%\n",
      "n_episode :80, score : 9.4, n_buffer : 786, eps : 7.6%\n",
      "n_episode :100, score : 10.0, n_buffer : 986, eps : 7.5%\n",
      "n_episode :120, score : 9.9, n_buffer : 1184, eps : 7.4%\n",
      "n_episode :140, score : 9.8, n_buffer : 1380, eps : 7.3%\n",
      "n_episode :160, score : 10.1, n_buffer : 1582, eps : 7.2%\n",
      "n_episode :180, score : 9.7, n_buffer : 1775, eps : 7.1%\n",
      "n_episode :200, score : 9.9, n_buffer : 1974, eps : 7.0%\n",
      "n_episode :220, score : 11.9, n_buffer : 2212, eps : 6.9%\n",
      "n_episode :240, score : 10.1, n_buffer : 2414, eps : 6.8%\n",
      "n_episode :260, score : 9.4, n_buffer : 2602, eps : 6.7%\n",
      "n_episode :280, score : 10.0, n_buffer : 2802, eps : 6.6%\n",
      "n_episode :300, score : 12.2, n_buffer : 3047, eps : 6.5%\n",
      "n_episode :320, score : 14.8, n_buffer : 3342, eps : 6.4%\n",
      "n_episode :340, score : 14.8, n_buffer : 3639, eps : 6.3%\n",
      "n_episode :360, score : 72.2, n_buffer : 5084, eps : 6.2%\n",
      "n_episode :380, score : 119.0, n_buffer : 7465, eps : 6.1%\n",
      "n_episode :400, score : 192.4, n_buffer : 11314, eps : 6.0%\n",
      "n_episode :420, score : 200.0, n_buffer : 15314, eps : 5.9%\n",
      "n_episode :440, score : 222.7, n_buffer : 19768, eps : 5.8%\n",
      "n_episode :460, score : 157.6, n_buffer : 22919, eps : 5.7%\n",
      "n_episode :480, score : 128.4, n_buffer : 25488, eps : 5.6%\n",
      "n_episode :500, score : 195.6, n_buffer : 29400, eps : 5.5%\n",
      "n_episode :520, score : 169.4, n_buffer : 32789, eps : 5.4%\n",
      "n_episode :540, score : 210.9, n_buffer : 37007, eps : 5.3%\n",
      "n_episode :560, score : 238.5, n_buffer : 41777, eps : 5.2%\n",
      "n_episode :580, score : 253.7, n_buffer : 46850, eps : 5.1%\n",
      "n_episode :600, score : 234.7, n_buffer : 50000, eps : 5.0%\n",
      "n_episode :620, score : 281.1, n_buffer : 50000, eps : 4.9%\n",
      "n_episode :640, score : 209.5, n_buffer : 50000, eps : 4.8%\n",
      "n_episode :660, score : 214.2, n_buffer : 50000, eps : 4.7%\n",
      "n_episode :680, score : 216.2, n_buffer : 50000, eps : 4.6%\n",
      "n_episode :700, score : 160.2, n_buffer : 50000, eps : 4.5%\n",
      "n_episode :720, score : 228.8, n_buffer : 50000, eps : 4.4%\n",
      "n_episode :740, score : 214.2, n_buffer : 50000, eps : 4.3%\n",
      "n_episode :760, score : 152.8, n_buffer : 50000, eps : 4.2%\n",
      "n_episode :780, score : 209.8, n_buffer : 50000, eps : 4.1%\n",
      "n_episode :800, score : 241.8, n_buffer : 50000, eps : 4.0%\n",
      "n_episode :820, score : 283.9, n_buffer : 50000, eps : 3.9%\n",
      "n_episode :840, score : 249.3, n_buffer : 50000, eps : 3.8%\n",
      "n_episode :860, score : 245.3, n_buffer : 50000, eps : 3.7%\n",
      "n_episode :880, score : 210.9, n_buffer : 50000, eps : 3.6%\n",
      "n_episode :900, score : 293.9, n_buffer : 50000, eps : 3.5%\n",
      "n_episode :920, score : 321.6, n_buffer : 50000, eps : 3.4%\n",
      "n_episode :940, score : 297.0, n_buffer : 50000, eps : 3.3%\n",
      "n_episode :960, score : 251.3, n_buffer : 50000, eps : 3.2%\n",
      "n_episode :980, score : 206.6, n_buffer : 50000, eps : 3.1%\n",
      "n_episode :1000, score : 234.9, n_buffer : 50000, eps : 3.0%\n",
      "n_episode :1020, score : 242.4, n_buffer : 50000, eps : 2.9%\n",
      "n_episode :1040, score : 197.4, n_buffer : 50000, eps : 2.8%\n",
      "n_episode :1060, score : 215.2, n_buffer : 50000, eps : 2.7%\n",
      "n_episode :1080, score : 214.9, n_buffer : 50000, eps : 2.6%\n",
      "n_episode :1100, score : 269.9, n_buffer : 50000, eps : 2.5%\n",
      "n_episode :1120, score : 303.9, n_buffer : 50000, eps : 2.4%\n",
      "n_episode :1140, score : 370.4, n_buffer : 50000, eps : 2.3%\n",
      "n_episode :1160, score : 338.8, n_buffer : 50000, eps : 2.2%\n",
      "n_episode :1180, score : 321.6, n_buffer : 50000, eps : 2.1%\n",
      "n_episode :1200, score : 236.4, n_buffer : 50000, eps : 2.0%\n",
      "n_episode :1220, score : 310.2, n_buffer : 50000, eps : 1.9%\n",
      "n_episode :1240, score : 350.1, n_buffer : 50000, eps : 1.8%\n",
      "n_episode :1260, score : 366.9, n_buffer : 50000, eps : 1.7%\n",
      "n_episode :1280, score : 238.8, n_buffer : 50000, eps : 1.6%\n",
      "n_episode :1300, score : 263.7, n_buffer : 50000, eps : 1.5%\n",
      "n_episode :1320, score : 321.4, n_buffer : 50000, eps : 1.4%\n",
      "n_episode :1340, score : 198.8, n_buffer : 50000, eps : 1.3%\n",
      "n_episode :1360, score : 198.4, n_buffer : 50000, eps : 1.2%\n",
      "n_episode :1380, score : 248.9, n_buffer : 50000, eps : 1.1%\n",
      "n_episode :1400, score : 343.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1420, score : 208.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1440, score : 226.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1460, score : 300.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1480, score : 292.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1500, score : 414.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1520, score : 333.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1540, score : 369.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1560, score : 221.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1580, score : 236.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1600, score : 177.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1620, score : 336.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1640, score : 319.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1660, score : 311.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1680, score : 233.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1700, score : 310.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1720, score : 299.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1740, score : 329.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1760, score : 316.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1780, score : 237.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1800, score : 228.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1820, score : 189.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1840, score : 233.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1860, score : 244.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1880, score : 245.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1900, score : 284.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1920, score : 298.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1940, score : 290.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1960, score : 205.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :1980, score : 252.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2000, score : 285.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2020, score : 366.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2040, score : 313.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2060, score : 295.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2080, score : 231.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2100, score : 233.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2120, score : 251.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2140, score : 247.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2160, score : 311.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2180, score : 211.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2200, score : 198.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2220, score : 200.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2240, score : 184.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2260, score : 209.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2280, score : 209.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2300, score : 238.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2320, score : 219.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2340, score : 220.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2360, score : 202.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2380, score : 260.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2400, score : 190.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2420, score : 166.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2440, score : 173.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2460, score : 203.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2480, score : 153.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2500, score : 230.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2520, score : 294.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2540, score : 258.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2560, score : 389.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2580, score : 183.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2600, score : 166.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2620, score : 195.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2640, score : 191.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2660, score : 193.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2680, score : 323.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2700, score : 238.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2720, score : 196.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2740, score : 239.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2760, score : 256.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2780, score : 257.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2800, score : 185.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2820, score : 126.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2840, score : 138.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2860, score : 177.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2880, score : 217.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2900, score : 281.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2920, score : 236.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2940, score : 241.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2960, score : 205.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :2980, score : 214.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3000, score : 197.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3020, score : 211.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3040, score : 228.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3060, score : 256.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3080, score : 292.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3100, score : 274.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3120, score : 263.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3140, score : 281.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3160, score : 279.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3180, score : 288.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3200, score : 192.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3220, score : 271.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3240, score : 232.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3260, score : 213.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3280, score : 245.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3300, score : 234.3, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3320, score : 226.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3340, score : 166.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3360, score : 165.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3380, score : 247.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3400, score : 182.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3420, score : 430.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3440, score : 312.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3460, score : 323.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3480, score : 391.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3500, score : 449.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3520, score : 413.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3540, score : 434.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3560, score : 389.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3580, score : 361.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3600, score : 331.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3620, score : 327.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3640, score : 276.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3660, score : 329.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3680, score : 359.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3700, score : 405.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3720, score : 442.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3740, score : 448.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3760, score : 477.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3780, score : 475.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3800, score : 446.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3820, score : 479.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3840, score : 489.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3860, score : 413.8, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3880, score : 444.9, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3900, score : 459.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3920, score : 402.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3940, score : 331.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3960, score : 325.2, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :3980, score : 449.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4000, score : 366.4, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4020, score : 244.0, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4040, score : 262.6, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4060, score : 100.5, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4080, score : 404.1, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4100, score : 449.7, n_buffer : 50000, eps : 1.0%\n",
      "n_episode :4120, score : 500.0, n_buffer : 50000, eps : 1.0%\n",
      "4121 종료 점수:  500.0\n"
     ]
    }
   ],
   "source": [
    "def is_record(episode_id):\n",
    "    # print(episode_id, end=' ')\n",
    "    if episode_id in is_record.st:\n",
    "        # print('<< 녹화 ', end=' ')\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "is_record.st = set()\n",
    "\n",
    "def main():\n",
    "    n_episode = 10000  # 에피소드 수\n",
    "    n_train_size = 2000  # 샘플  최소 이상일 때 학습\n",
    "    max_score = 500\n",
    "    env = gym.make('CartPole-v1')\n",
    "    env = wrappers.Monitor(env, \"./gym-results\", force=True, video_callable=is_record)\n",
    "    env._max_episode_steps = 10001\n",
    "    \n",
    "    q = Qnet()\n",
    "    q_target = Qnet()\n",
    "    q_target.load_state_dict(q.state_dict())\n",
    "    memory = ReplayBuffer()\n",
    "\n",
    "    print_interval = 20\n",
    "    video_interval = 50\n",
    "    score = 0.0  \n",
    "    optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
    "    \n",
    "    score_li = []\n",
    "    is_end = -1\n",
    "\n",
    "    for n_epi in range(n_episode):\n",
    "\n",
    "        if is_end > 0:\n",
    "            is_end -= 1\n",
    "            if is_end == 0:\n",
    "                break \n",
    "        \n",
    "        epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\n",
    "        s = env.reset()  # 현재 비디오 저장???\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            a = q.sample_action(torch.from_numpy(s).float(), epsilon)      \n",
    "            s_prime, r, done, info = env.step(a)  # 여기서 단계 진행하고 return되기 전에 프레임 저장??\n",
    "            done_mask = 0.0 if done else 1.0\n",
    "            memory.put((s,a,r/100.0,s_prime, done_mask))\n",
    "            s = s_prime\n",
    "\n",
    "            score += r\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        if memory.size()>n_train_size:\n",
    "            train(q, q_target, memory, optimizer)\n",
    "\n",
    "        if n_epi % print_interval == 0 and n_epi != 0:\n",
    "            q_target.load_state_dict(q.state_dict())\n",
    "            print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(\n",
    "                                                            n_epi, score/print_interval, memory.size(), epsilon*100))\n",
    "            score_li.append(score/print_interval)\n",
    "            if (is_end == -1 and score/print_interval >= max_score):\n",
    "                is_record.st.add(n_epi + 1)\n",
    "                print(n_epi + 1, \"종료 점수: \", score/print_interval)\n",
    "                is_end = 2  # 직후에 종료\n",
    "            score = 0.0\n",
    "        \n",
    "        # if not (n_epi + 1) % video_interval:\n",
    "        #     is_record.st.add(n_epi + 1)\n",
    "    env.close()\n",
    "    return env, n_episode\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    env, n_episode = main()\n",
    "    # print(is_record.st)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     n_episode = 5000  # 에피소드 수\n",
    "#     n_train_size = 2000  # 샘플  최소 이상일 때 학습\n",
    "#     max_score = 500\n",
    "#     env = gym.make('CartPole-v1')\n",
    "#     env = wrappers.Monitor(env, \"./gym-results\", force=True, video_callable=lambda episode_id: episode_id == n_episode - 1)\n",
    "\n",
    "#     q = Qnet()\n",
    "#     q_target = Qnet()\n",
    "#     q_target.load_state_dict(q.state_dict())\n",
    "#     memory = ReplayBuffer()\n",
    "\n",
    "#     print_interval = 20\n",
    "#     score = 0.0  \n",
    "#     optimizer = optim.Adam(q.parameters(), lr=learning_rate)\n",
    "    \n",
    "#     score_li = []\n",
    "\n",
    "#     for n_epi in range(n_episode):\n",
    "#         epsilon = max(0.01, 0.08 - 0.01*(n_epi/200)) #Linear annealing from 8% to 1%\n",
    "#         s = env.reset()  # 현재 비디오 저장\n",
    "#         done = False\n",
    "\n",
    "#         while not done:\n",
    "#             a = q.sample_action(torch.from_numpy(s).float(), epsilon)      \n",
    "#             s_prime, r, done, info = env.step(a)  # 여기서 단계 진행하고 return되기 전에 프레임 저장\n",
    "#             done_mask = 0.0 if done else 1.0\n",
    "#             memory.put((s,a,r/100.0,s_prime, done_mask))\n",
    "#             s = s_prime\n",
    "\n",
    "#             score += r\n",
    "#             if done:\n",
    "#                 break\n",
    "            \n",
    "#         if memory.size()>n_train_size:\n",
    "#             train(q, q_target, memory, optimizer)\n",
    "\n",
    "#         if n_epi % print_interval == 0 and n_epi != 0:\n",
    "#             q_target.load_state_dict(q.state_dict())\n",
    "#             print(\"n_episode :{}, score : {:.1f}, n_buffer : {}, eps : {:.1f}%\".format(\n",
    "#                                                             n_epi, score/print_interval, memory.size(), epsilon*100))\n",
    "#             score_li.append(score/print_interval)\n",
    "#             if (score/print_interval >= max_score):\n",
    "#                 break\n",
    "#             score = 0.0\n",
    "#     env.close()\n",
    "#     return env, n_episode\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     env, n_episode = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# video_url = './gym-results/openaigym.video.{0}.video{1:0>6}.mp4'.format(env.file_infix, n_episode-1)\n",
    "# Video(video_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}