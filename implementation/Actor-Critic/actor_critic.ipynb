{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import gym      # environment 라이브러리\r\n",
    "import torch    # pytorch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torch.optim as optim\r\n",
    "from torch.distributions import Categorical\r\n",
    "\r\n",
    "# Hyperparameters\r\n",
    "learning_rate = 0.0002\r\n",
    "gamma = 0.98\r\n",
    "n_rollout = 10"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class ActorCritic(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(ActorCritic, self).__init__()\r\n",
    "        self.data = []\r\n",
    "        \r\n",
    "        # 이번엔 REINFORCE와 다르게 네트워크가 3개이다. \r\n",
    "        # fc1에서 두 개로 갈라져서 fc_pi와 fc_v로 간다.\r\n",
    "\r\n",
    "        # 현재 state를 256개 수로 인코딩했다고 이해하면 된다.\r\n",
    "        self.fc1 = nn.Linear(4,256) \r\n",
    "        # 256개에서 pi를 나타내는 2개로 \r\n",
    "        self.fc_pi = nn.Linear(256,2) \r\n",
    "        # 256개에서 v를 나타내는 1개로\r\n",
    "        self.fc_v = nn.Linear(256,1)\r\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=learning_rate)\r\n",
    "        \r\n",
    "    def pi(self, x, softmax_dim = 0):\r\n",
    "        x = F.relu(self.fc1(x))\r\n",
    "        x = self.fc_pi(x)\r\n",
    "        # 확률분포이기 때문에 softmax 취함.\r\n",
    "        prob = F.softmax(x, dim=softmax_dim)\r\n",
    "        return prob\r\n",
    "    \r\n",
    "    def v(self, x):\r\n",
    "        x = F.relu(self.fc1(x))\r\n",
    "        v = self.fc_v(x)\r\n",
    "        return v\r\n",
    "    \r\n",
    "    def put_data(self, transition):\r\n",
    "        self.data.append(transition)\r\n",
    "        \r\n",
    "    def make_batch(self):\r\n",
    "        # batch로 학습하면 learning-rate에 덜 민감해지고, 학습이 잘 된다.\r\n",
    "        s_lst, a_lst, r_lst, s_prime_lst, done_lst = [], [], [], [], []\r\n",
    "        for transition in self.data:\r\n",
    "            s,a,r,s_prime,done = transition\r\n",
    "            s_lst.append(s)\r\n",
    "            a_lst.append([a])\r\n",
    "            r_lst.append([r/100.0])\r\n",
    "            s_prime_lst.append(s_prime)\r\n",
    "            done_mask = 0.0 if done else 1.0\r\n",
    "            done_lst.append([done_mask])\r\n",
    "        \r\n",
    "        tmp = torch.tensor(s_lst, dtype=torch.float), \\\r\n",
    "                            torch.tensor(a_lst), \\\r\n",
    "                            torch.tensor(r_lst, dtype=torch.float), \\\r\n",
    "                            torch.tensor(s_prime_lst, dtype=torch.float), \\\r\n",
    "                            torch.tensor(done_lst, dtype=torch.float)\r\n",
    "        s_batch, a_batch, r_batch, s_prime_batch, done_batch = tmp\r\n",
    "        self.data = []\r\n",
    "        return s_batch, a_batch, r_batch, s_prime_batch, done_batch\r\n",
    "  \r\n",
    "    def train_net(self):\r\n",
    "        s, a, r, s_prime, done = self.make_batch()\r\n",
    "        # td target과 delta 식 그 자체임\r\n",
    "        td_target = r + gamma * self.v(s_prime) * done\r\n",
    "        delta = td_target - self.v(s)\r\n",
    "        \r\n",
    "        # 확률 분포를 얻어서\r\n",
    "        pi = self.pi(s, softmax_dim=1)\r\n",
    "        pi_a = pi.gather(1,a)\r\n",
    "        # detach() 메소드는 원본 tensor에서 gradient 전파를 방지하는 tensor를 생성한다.\r\n",
    "        # storage를 공유하기 때문에 원본 tensor가 변하면 같이 바뀐다.\r\n",
    "        loss = -torch.log(pi_a) * delta.detach() + F.smooth_l1_loss(self.v(s), td_target.detach())\r\n",
    "\r\n",
    "        self.optimizer.zero_grad()\r\n",
    "        loss.mean().backward()\r\n",
    "        self.optimizer.step()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def main():  \r\n",
    "    env = gym.make('CartPole-v1')\r\n",
    "    # policy 대신 model class를 만들었다. \r\n",
    "    # actor-critic 둘 다 있어야 하기 때문에 policy와 value를 둘 다 얻을 수 있게 함.\r\n",
    "    model = ActorCritic()    \r\n",
    "    print_interval = 20\r\n",
    "    score = 0.0\r\n",
    "\r\n",
    "    for n_epi in range(10000):\r\n",
    "        done = False\r\n",
    "        s = env.reset()\r\n",
    "        while not done:\r\n",
    "            for t in range(n_rollout):\r\n",
    "                # 확률 분포 구하고\r\n",
    "                prob = model.pi(torch.from_numpy(s).float())\r\n",
    "                # 확률 분포 모델 만들고\r\n",
    "                m = Categorical(prob)\r\n",
    "                # 샘플링하고\r\n",
    "                a = m.sample().item()\r\n",
    "                # 환경에 넘겨주고 다음 observation 얻고\r\n",
    "                s_prime, r, done, info = env.step(a)\r\n",
    "                # TD의 경우 매번 학습이 가능하지만 모아서 batch learning 하니까 학습이 더 잘 됐다.\r\n",
    "                model.put_data((s,a,r,s_prime,done))\r\n",
    "                \r\n",
    "                s = s_prime\r\n",
    "                score += r\r\n",
    "\r\n",
    "                if score/print_interval > 400:\r\n",
    "                    env.render()\r\n",
    "                \r\n",
    "                if done:\r\n",
    "                    break                     \r\n",
    "            \r\n",
    "            model.train_net()\r\n",
    "            \r\n",
    "        if n_epi%print_interval==0 and n_epi!=0:\r\n",
    "            print(\"# of episode :{}, avg score : {:.1f}\".format(n_epi, score/print_interval))\r\n",
    "            score = 0.0\r\n",
    "    env.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "if __name__ == '__main__':\r\n",
    "    main()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('py38-pytorch-gpu': conda)"
  },
  "interpreter": {
   "hash": "92bb61e8f2b0dcdaa21cd71aad1d97e3da046ad8a677ac321cbd25d595832889"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}